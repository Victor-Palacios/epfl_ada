{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Applied ML\n",
    "\n",
    "\n",
    "### Loading the data\n",
    "First we load the data and vectorize it.\n",
    "The library functions contained in sklearn make this very straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the builtin function for loading data\n",
    "# sklearn already has a split in train/test, you can specify which data you want with the \"subset\" parameter\n",
    "# since we will perform that split ourselves, we load all data\n",
    "# we also remove all metadata\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset=\"all\", remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target', 'data', 'DESCR', 'description', 'target_names', 'filenames'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the newsgroups are an sklearn \"bunch\"\n",
    "# it resembles a dictionary\n",
    "newsgroups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\\nare killing those Devils worse than I thought. Jagr just showed you why\\nhe is much better than his regular season stats. He is also a lot\\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\\nregular season game.          PENS RULE!!!\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data contains the text for each article\n",
    "newsgroups.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many articles we have\n",
    "len(newsgroups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(18846, 134410)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# this will create a vector for every article\n",
    "# the output is a matrix\n",
    "matrix = TfidfVectorizer().fit_transform(newsgroups.data)\n",
    "\n",
    "print(type(matrix))\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "We split the data into separate sets for training, testing and evaluating.\n",
    "Following the usual naming convention in machine learning, we call these datasets\n",
    "\n",
    " - X_train, y_train\n",
    " - X_test, y_test\n",
    " - X_val, y_val\n",
    " \n",
    "where X is the data and y contains the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renaming\n",
    "X = matrix\n",
    "y = newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we do the split into train, test, val\n",
    "# it's 0.8, 0.1, 0.1\n",
    "\n",
    "num_samples = len(y)\n",
    "num_train = int(0.8 * num_samples)\n",
    "num_test = int(0.1 * num_samples)\n",
    "num_val = int(0.1 * num_samples)\n",
    "\n",
    "X_train = X[:num_train]\n",
    "X_test = X[num_train : -num_val]\n",
    "X_val = X[-num_val:]\n",
    "\n",
    "\n",
    "y_train = y[:num_train]\n",
    "y_test = y[num_train : -num_val]\n",
    "y_val = y[-num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABZCAYAAAAaRaGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06696a2748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we know whether the data is ordered\n",
    "# it would be possible that we have all articles from category 1 first, then category 2, etc\n",
    "# this would mean that our split is broken\n",
    "# we take a look at the labels\n",
    "# the scatterplot shows that there is no order, the labels don't increase linearly\n",
    "plt.figure(figsize=(10,1))\n",
    "plt.scatter(np.arange(len(y)), y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a RandomForest\n",
    "\n",
    "Before we start the grid search, we fit a random forest, to see how the syntax looks.\n",
    "\n",
    "We also want to check whether the classifier actually works, or if we have made some mistake. There are 20 categories. If the classifier is just guessing randomly, we would see an accuracy of about 1/20 = 5%. If the classifier does better than that, it is able to \"learn\" the data. That would mean we can continue to search for a good parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the classifier to predict labels for the test set\n",
    "pred_test = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on the test set is:  0.45652173913\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy\n",
    "comparison = pred_test == y_test\n",
    "hits = comparison.sum()\n",
    "accuracy = hits / len(comparison)\n",
    "print(\"the accuracy on the test set is: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This random forest is able to achieve 46% test accuracy. And this is for top-1 results. It would probably do much better if we would compute something like the top-2 or top-3 accuracy.\n",
    "\n",
    "The number of estimators is 10 by default. I would like to get the max depth that was used in this tree. Then we can use these parameters as the center of our grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth is:  609\n",
      "avg depth is:  496.2\n"
     ]
    }
   ],
   "source": [
    "# unfortunately, we are apparently not supposed to read the depth\n",
    "# it is necessary to use properties with _ in their name\n",
    "depths = [estimator.tree_.max_depth for estimator in random_forest.estimators_]\n",
    "\n",
    "\n",
    "max_depth = max(depths)\n",
    "avg_depth = sum(depths)/len(depths)\n",
    "\n",
    "print(\"max depth is: \", max_depth)\n",
    "print(\"avg depth is: \", avg_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch\n",
    "\n",
    "We use the parameters given above to set up our gridsearch.\n",
    "The number of estimators is 10 by default. It seems reasonable to look at numbers from 5 to 15.\n",
    "That means 50% above and 50% below.\n",
    "\n",
    "So far the maximum depth was 550. We are changing the number of estimators, but I don't expect the maximum depth to go much higher than this. So I'm limiting it to 700."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = np.arange(10)+5\n",
    "max_depths = 7 * np.logspace(1, 2, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  70.        ,   90.40847655,  116.7670376 ,  150.8104283 ,\n",
       "        194.77915815,  251.56695647,  324.91121835,  419.63897522,\n",
       "        541.98457788,  700.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [0] * X_train.shape[0]\n",
    "test_indices = [1] * X_test.shape[0]\n",
    "indices = train_indices + test_indices\n",
    "\n",
    "X_joint = vstack([X_train, X_test])\n",
    "y_joint = np.concatenate([y_train, y_test])\n",
    "\n",
    "pds = PredefinedSplit(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = True\n",
    "\n",
    "if rerun:\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    clf_grid = GridSearchCV(rfc, param_grid={'n_estimators':n_estimators, 'max_depth':max_depths}, cv=pds)\n",
    "    clf_grid.fit(X_joint, y_joint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

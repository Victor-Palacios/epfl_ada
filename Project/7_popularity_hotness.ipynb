{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity of songs (song hotness, or \"hotttnesss\" ???)\n",
    "In this section we are going to look at the million-song dataset and we are going to try to get the popularity of a song. The million-song dataset has a special structure. There are 26 folders A, B, C, ..., Z. Folder A has recursively 26 subfolders which have again 26 subfolders and so on and the last subfolders have a certain number of h5 files. Each of these h5 files contain all information about one track and the name of the file is simply the track id followed by the extension \".h5\". \n",
    "\n",
    "Now the size of the dataset is pretty challenging since the compressed files A.tar.gz, B.tar.gz, ..., Z.tar.gz each have a size of approximately 7.5Gb. So we will start by taking a closer look at the A.tar.gz sample. For that we go to the cluster with ssh, we download A.tar.gz to our home folder and then we simply use scp on our computer to go grab that A.tar.gz file. Now, on our computer we unzip A.tar.gz and now we have a nice A folder containing the 26-th of all our songs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "base_dir_data = r'../../'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read one track with our `h5py` tool just to see where everything is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(os.path.join(base_dir_data, \"A/A/A/TRAAAAK128F9318786.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to open this file manually with [HDFView](https://support.hdfgroup.org/products/java/hdfview/) in order to inspect it before doing any code analysis. We see that it has 3 folders: analysis, metadata and musicbrainz. The analysis folder contains all the information about the musical instruments and how they're played. This is clearly the biggest folder. The musicbrainz doesn't seem to contain much. It could be useful if we decide to use the [MusicBrainz](https://musicbrainz.org/) website. Anyway, we are interested in the metadata folder and more precisely in the metadata/songs file. That file contains the \"song_hotttnesss\" (can't understand why 3 \"t\"s and 3 \"s\"s attribute which seems to be a value between 0 and 1 and this attribute corresponds to the popularity the song. So let's get it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_songs = f[\"metadata/songs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CLASS', b'TABLE'),\n",
       " ('VERSION', b'2.6'),\n",
       " ('TITLE', b'table of metadata for one song'),\n",
       " ('FIELD_0_NAME', b'analyzer_version'),\n",
       " ('FIELD_1_NAME', b'artist_7digitalid'),\n",
       " ('FIELD_2_NAME', b'artist_familiarity'),\n",
       " ('FIELD_3_NAME', b'artist_hotttnesss'),\n",
       " ('FIELD_4_NAME', b'artist_id'),\n",
       " ('FIELD_5_NAME', b'artist_latitude'),\n",
       " ('FIELD_6_NAME', b'artist_location'),\n",
       " ('FIELD_7_NAME', b'artist_longitude'),\n",
       " ('FIELD_8_NAME', b'artist_mbid'),\n",
       " ('FIELD_9_NAME', b'artist_name'),\n",
       " ('FIELD_10_NAME', b'artist_playmeid'),\n",
       " ('FIELD_11_NAME', b'genre'),\n",
       " ('FIELD_12_NAME', b'idx_artist_terms'),\n",
       " ('FIELD_13_NAME', b'idx_similar_artists'),\n",
       " ('FIELD_14_NAME', b'release'),\n",
       " ('FIELD_15_NAME', b'release_7digitalid'),\n",
       " ('FIELD_16_NAME', b'song_hotttnesss'),\n",
       " ('FIELD_17_NAME', b'song_id'),\n",
       " ('FIELD_18_NAME', b'title'),\n",
       " ('FIELD_19_NAME', b'track_7digitalid'),\n",
       " ('FIELD_0_FILL', b''),\n",
       " ('FIELD_1_FILL', 0),\n",
       " ('FIELD_2_FILL', 0.0),\n",
       " ('FIELD_3_FILL', 0.0),\n",
       " ('FIELD_4_FILL', b''),\n",
       " ('FIELD_5_FILL', 0.0),\n",
       " ('FIELD_6_FILL', b''),\n",
       " ('FIELD_7_FILL', 0.0),\n",
       " ('FIELD_8_FILL', b''),\n",
       " ('FIELD_9_FILL', b''),\n",
       " ('FIELD_10_FILL', 0),\n",
       " ('FIELD_11_FILL', b''),\n",
       " ('FIELD_12_FILL', 0),\n",
       " ('FIELD_13_FILL', 0),\n",
       " ('FIELD_14_FILL', b''),\n",
       " ('FIELD_15_FILL', 0),\n",
       " ('FIELD_16_FILL', 0.0),\n",
       " ('FIELD_17_FILL', b''),\n",
       " ('FIELD_18_FILL', b''),\n",
       " ('FIELD_19_FILL', 0),\n",
       " ('NROWS', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(metadata_songs.attrs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we see that the \"FIELD_16_NAME\" corresponds to the song hotness attribute. let's look with closer details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (b'', 324573,  0.63990252,  0.46131834, b'ARJNIUY12298900C91',  nan, b'',  nan, b'6ae6a016-91d7-46cc-be7d-5e8e5d320c54', b'Adelitas Way', 166043, b'', 0, 0, b'Adelitas Way', 497103,  0.73337162, b'SOBLFFE12AF72AA5BA', b'Scream', 5504670)],\n",
       "      dtype=[('analyzer_version', 'S32'), ('artist_7digitalid', '<i4'), ('artist_familiarity', '<f8'), ('artist_hotttnesss', '<f8'), ('artist_id', 'S32'), ('artist_latitude', '<f8'), ('artist_location', 'S1024'), ('artist_longitude', '<f8'), ('artist_mbid', 'S40'), ('artist_name', 'S1024'), ('artist_playmeid', '<i4'), ('genre', 'S1024'), ('idx_artist_terms', '<i4'), ('idx_similar_artists', '<i4'), ('release', 'S1024'), ('release_7digitalid', '<i4'), ('song_hotttnesss', '<f8'), ('song_id', 'S32'), ('title', 'S1024'), ('track_7digitalid', '<i4')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_songs.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we see that the song hotness is the element at index 16 of the `value` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333716199617285"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_songs.value[0][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to generalize this to all of A folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_files(basedir, ext='.h5'):\n",
    "    hotness = []\n",
    "    track_ids = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root, '*'+ext))\n",
    "        for f in files:\n",
    "            h5_file = h5py.File(str(f))\n",
    "            song_hotttnesss = h5_file[\"metadata/songs\"].value[0][16]\n",
    "            track_ids.append(f.split(\"/\")[-1].split(\".\")[0])\n",
    "            hotness.append(song_hotttnesss)\n",
    "    return pd.DataFrame(data={\"id\" : track_ids, \"hotttnesss\": hotness})\n",
    "\n",
    "song_hotness_A = count_all_files(r'../../A/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it ! We now have a nice pandas frame containing the track ids with the hotness of the corresponding song:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotttnesss</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>TRARRQU128F427DAD3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.524822</td>\n",
       "      <td>TRARRAO128F145D072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TRARRWA128F42A0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204543</td>\n",
       "      <td>TRARRYB128F426BC39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TRARRNK12903D0C0DA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hotttnesss                  id\n",
       "0    0.000000  TRARRQU128F427DAD3\n",
       "1    0.524822  TRARRAO128F145D072\n",
       "2         NaN  TRARRWA128F42A0195\n",
       "3    0.204543  TRARRYB128F426BC39\n",
       "4         NaN  TRARRNK12903D0C0DA"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not convinced, you can take rows at random and go see in the h5 file if the value you have corresponds to the value \"song_hotttnesss\" in the h5 file. Now we will need a fast way to find a song given its track id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness_A = song_hotness_A.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotttnesss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRARRQU128F427DAD3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARRAO128F145D072</th>\n",
       "      <td>0.524822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARRWA128F42A0195</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARRYB128F426BC39</th>\n",
       "      <td>0.204543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARRNK12903D0C0DA</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    hotttnesss\n",
       "id                            \n",
       "TRARRQU128F427DAD3    0.000000\n",
       "TRARRAO128F145D072    0.524822\n",
       "TRARRWA128F42A0195         NaN\n",
       "TRARRYB128F426BC39    0.204543\n",
       "TRARRNK12903D0C0DA         NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we don't want to lose this so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness_A.to_csv(os.path.join(base_dir_data, \"csv_hotness_files/A_hotness.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it ! We have our csv data for A. But now we have 25 other folders to process and there's no way we are going to download each manually on our small computers (moreover it takes much time to download them). So this is what we are doing. We are creating a bash script for processing all the files directly on the cluster:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "set -e\n",
    "\n",
    "declare -a filenames=(\"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\"\n",
    "            \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\")\n",
    "\n",
    "for letter in \"${filenames[@]}\"\n",
    "do\n",
    "    eval \"hadoop fs -getmerge /datasets/million-song/$letter.tar.gz ~/$letter.tar.gz\"\n",
    "    eval \"tar -zxvf $letter.tar.gz\"\n",
    "    eval \"rm $letter.tar.gz\"\n",
    "    eval \"python script_h5_to_csv.py $letter\"\n",
    "    eval \"rm -r $letter\"\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in short, we copy the hdfs file to our local folder, we unzip it, we remove the compressed version, we process it and get the csv the same way we did it for A and, finally, we remove the folder (yes I am too lazy to go search how we convert ASCII numbers to characters in bash so I created the alphabet array manually). The \"script_h5_to_csv.py\" contains the following code (which is the same we did for A above in the notebook):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "def count_all_files(basedir, ext='.h5'):\n",
    "    hotness = []\n",
    "    track_ids = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root, '*'+ext))\n",
    "        for f in files:\n",
    "            h5_file = h5py.File(str(f))\n",
    "            song_hotttnesss = h5_file[\"metadata/songs\"].value[0][16]\n",
    "            track_ids.append(f.split(\"/\")[-1].split(\".\")[0])\n",
    "            hotness.append(song_hotttnesss)\n",
    "    return pd.DataFrame(data={\"id\" : track_ids, \"hotttnesss\": hotness})\n",
    "\n",
    "song_hotness_A = count_all_files(sys.argv[1])\n",
    "song_hotness_A.to_csv(\"{}_hotness.csv\".format(sys.argv[1]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [tmux](https://github.com/tmux/tmux/wiki) to let the script run during the night and that's it, We have our csv files containing the hotness for our entire set of one million songs !\n",
    "\n",
    "Now we want to combine this information with the [Musixmatch](https://www.musixmatch.com/fr) lyrics dataset because we need the lyrics if we want to do any processing. This is why we are going to keep only the tracks for which we have the lyrics. So let's get all those tracks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TRAAAAV128F421A322',),\n",
       " ('TRAAABD128F429CF47',),\n",
       " ('TRAAAED128E0783FAB',),\n",
       " ('TRAAAEF128F4273421',),\n",
       " ('TRAAAEW128F42930C0',)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../../mxm_dataset.db.1\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT DISTINCT track_id FROM lyrics ORDER BY track_id;\")\n",
    "track_ids = cursor.fetchall()\n",
    "cursor.close()\n",
    "track_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all hotness csv files into one big dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_hotness_files = glob.glob(os.path.join(base_dir_data, \"csv_hotness_files/*_hotness.csv\"))\n",
    "\n",
    "list_all_frames = []\n",
    "for csv in all_csv_hotness_files:\n",
    "    df = pd.read_csv(csv)\n",
    "    list_all_frames.append(df[[\"id\", \"hotttnesss\"]])\n",
    "\n",
    "song_hotness = pd.concat(list_all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, we have one million songs ! Now let's just save this dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness.to_csv(os.path.join(base_dir_data, \"csv_hotness_files/hotness.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness = song_hotness.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we take only the songs where we have the lyrics in the Musixmatch dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237662/237662 [2:19:48<00:00, 28.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_lyrics_only_hotness():\n",
    "    result = pd.DataFrame(columns=[\"hotness\"])\n",
    "    for i in tqdm(range(len(track_ids))):\n",
    "        track_id = track_ids[i][0]\n",
    "        if track_id in song_hotness.index:\n",
    "            hotness = song_hotness.loc[track_id][\"hotttnesss\"]\n",
    "            result.loc[track_id] = [hotness]\n",
    "    return result\n",
    "\n",
    "song_hotness_lyrics = get_lyrics_only_hotness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow ! Lasted more than 2 hours on a laptop. Probably should have done it on the cluster (or optimized it a little bit) We can't lose this so let's save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness_lyrics.to_csv(os.path.join(base_dir_data, \"csv_hotness_files/hotness_lyrics.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our dataframe with the popularity (hotness) for all songs where we have lyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAAAAV128F421A322</th>\n",
       "      <td>0.481694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAABD128F429CF47</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAED128E0783FAB</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAEF128F4273421</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAEW128F42930C0</th>\n",
       "      <td>0.407902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hotness\n",
       "TRAAAAV128F421A322  0.481694\n",
       "TRAAABD128F429CF47       NaN\n",
       "TRAAAED128E0783FAB       NaN\n",
       "TRAAAEF128F4273421       NaN\n",
       "TRAAAEW128F42930C0  0.407902"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness_lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we see that there are a lot of NaN values (songs for which the popularity was not measured). Let's just describe the frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.475753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.360371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.508289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.621942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             hotness\n",
       "count  170573.000000\n",
       "mean        0.475753\n",
       "std         0.209909\n",
       "min         0.000000\n",
       "25%         0.360371\n",
       "50%         0.508289\n",
       "75%         0.621942\n",
       "max         1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness_lyrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the min is 0 and the max is 1, which indicates that we didn't do mistakes and that the dataset is pretty clean (there are no strange negative or greater than 1 values). We also see that we have 170573 \"usable\" datapoints, i.e. songs where we have the hotness value and the lyrics for further offensiveness analysis. On the one hand, that's less than 20% of the million songs but one the other it is still 170 thousands which makes quite a lot of data ! Let's plot the histograms here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff064751128>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff05dd20e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "song_hotness_lyrics.hotness.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to look like a gaussian, except for these 0 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14756 songs with hotness 0\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} songs with hotness 0\".format(song_hotness_lyrics[song_hotness_lyrics[\"hotness\"] == 0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That makes almost 15000 songs for which we are somehow \"unsure\" about. Are those really songs with 0 popularity ?! Maybe they really didn't touch anyone or very few people. But let's look at the bright side: even if we cut them out in our analysis, we are still left with approximately 155000 songs for which we know the popularity value and the lyrics. But we still have to decide what we will do with these 15000 songs, will we keep them or exclude them ? Maybe we will keep them and treat them separately also. \n",
    "\n",
    "Anyway, Million Song and Echo Nest have our back covered: we can use another popularity measure which is the play count ! But this value is present in [another dataset](https://labrosa.ee.columbia.edu/millionsong/tasteprofile). If this doesn't work work we might also use the [Yahoo ratings dataset](https://labrosa.ee.columbia.edu/millionsong/pages/tasks-demos#yahoodata) but this one is for artist rating more than song rating so we should be careful if we decide to include it too. So let's proceed with Taste Profile !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

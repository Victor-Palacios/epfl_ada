%
% File acl2014.tex
%
% Contact: giovanni.colavizza@epfl.ch
%%
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Data Science for Good: Song offensiveness vs time and popularity}

\author{Lars Klein \\
  {\tt privatlarsklein@gmail.com} \\\And
  \\Ahmed Kulovic \\
  {\tt ahmed.kulovic@epfl.ch} \\\And
Ali Hosseiny \\
{\tt ali.hosseiny@epfl.ch} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
We investigate the development of colloquial language by looking at music. 
Popular music is mostly free of censorship and can be used as a repository of common expressions and phrases. 
We analyse the lyrics collected in the MusixMatch database and develop a scheme to classify the “offensiveness” of a song. 
In a first step, we investigate whether offensiveness is increasing over time. Then we correlate the offensiveness of a song with its popularity. 
The 1 Million Song Database contains information on how often individual users have played a song, as well as a "hotness" attribute which relates to the popular appeal of a song.
While there seems to be some correlation with time, we couldn't find any significant relationship between popularity and offensiveness.
\end{abstract}



\section{Introduction}

Today people take great pains to fight against all kinds of discrimination. 
One word out of line can cause online witch hunts. 
With our research, we tried to determine if this is honest, or a big hypocrisy: 
Are people really concerned or is offensiveness actually becoming more popular ?

\subsection{Datasets}

Our primary dataset is the million song dataset (\textbf{MSD}) (TODO: quote).
For each song, there is a rich collection of metadata, such as the time of release and a value for "hotness".
The MSD also provides the infrastructure for various additional datasets. The key component here is a song id
which serves to identify each song in the MSD and connects it to other datasets.\\
As an additional resource for information on popularity, we use the tasteprofile (TODO: quote) dataset.
It is a collaboration with \textit{echo nest} (TODO: quote) and contains the number of times each song has been played.\\
To analyze lyrics we integrate the musixmatch (TODO: quote) dataset. Due to copyright, the dataset doesn't contain the raw lyrics,
instead it offers a bag-of-words. The authors have compiled a list of the 5000 most used word-stems. An entry in the dataset contains
the number of times each word stem occurs in the lyrics of a specific song.

\subsection{Offensiveness}
A first step is to rate the offensiveness of a song. Since we don't have complete lyrics, but only a bag-of-words, we can't look at offensive phrases.
We need a list of offensive words to search for in the lyrics of a song. Compiling this list manually is not a good option, none of us is a native english speaker. We cannot adequately judge the 
offensiveness of a word and our list would be bound to be very incomplete.\\
Instead we are using a survey organized by the british telecommunications regulator OFCOM (TODO: quote). In this survey, 248 british citizens were asked to rank a selection of swearwords by their offensiveness.
We have imported this list and checked for matches against the word-stems in musixmatch. Based on our findings, we cleaned the list. For example: The musixmatch lyrics cover not only english songs.
The word "negro" is a strong insult according to the OFCOM ranking, but in spanish it is simply a color.
Another problem is "god", ofcom ranks this as an offensive word. That might be true if it is used as an expletive "God!". We have still removed "god" from our list.\
In a second step we went through the 5000 word-stems and searched for offensive words that were not covered by OFCOM.
We could use the OFCOM rating as a guideline on how to judge their offensiveness.

\subsection{Popularity}
A record in the MSD dataset contains a "hotness" field. This field is supposed to rank the popular appeal of a song on a scale from 0 to 1.
Unfortunately, the exact meaning is not clearly documented. And the value is missing for many songs. (TODO: how many).\\

Therefore we have also included the tasteprofile dataset. This has been recorded by echo nest and contains tuples of user ids, song ids and playcounts.
For each user and each song, the dataset records how often this user has played the song. We group the data by the song id and aggregate the playcount.
This gives us the total number of times a song has been played. We believe that this is a good measure of its popularity.
\section{Analysis}

\subsection{Basic correlations}

As a first orientation, we searched for correlations between the fields we have recorded. This was done without any rescaling of features or filtering.\\
To rate the offensiveness, we have counted the total number of offensive words in a song.
Our results are shown on figure \ref{basic_correlations}. The plot doesn't show any correlation between offensiveness and popularity. Of course this doesn't mean that there is no dependency between them.
Correlations mean linear dependencies between values. This could be nonlinear. It is also possible that our data cleaning was not a good choice.
\begin{figure*}

\includegraphics{plots/basic_correlations}
\caption{Basic correlations for all songs}
\label{basic_correlations}
\end{figure*}

We have investigated the effect of other scaling and filtering schemes, such as:

\begin{itemize}
\item we have tried using the logarithm of the play count instead of the original number of times the songs have been played. This was because the songs which were played often could have a huge value as compared to the ones which were played only 1, 2, 3, or a few times. We wanted to smooth those values so that the difference between popular and non popular songs can be better measured. Unfortunately this didn't give us better correlations than before. However we notice that the correlation between song hotness and play counts suddenly jumped from 0.13 to 0.51 so, at least, we got some insights about the way the song hotness was computed in the Million Songs dataset: they probably also used the logarithm of the play counts value as one of the measures of popularity.
\item We removed songs where the play count was very low hoping that the data was better for more popular songs. So we took only songs that were played at least 4 times. Unfortunately, we still didn't get any improvement out of this.
\item In the same spirit as the previous one we tried to keep only recent songs (we tried both with songs which were released after 1990 and those which were released after 2000). We hoped that the data was better for recent songs and that we could get some meaningful correlations with this strategy, but nothing: the correlations are still close to zero.
 \end{itemize}


\subsection{Correlations over time}
Since we didn't get meaningful correlations using all songs at once, it might be interesting to include the temporal dimension and try to figure out whether there are correlations for specific years. We show the results on figure \ref{correlation_time}.

\begin{figure*}
\includegraphics[width=\linewidth]{plots/correlation_time}
\caption{Correlation between song offensiveness and popularity over time}
\label{correlation_time}
\end{figure*}

As we see there are no correlations except in the beginning of the time period of the Million Song dataset. Unfortunately, we have very few songs for that time period and we tried to get more insights on them (see the chapter on Ratio experiments). Before giving more details let us take a closer look at figure \ref{correlation_time_categories}. We have plotted the same correlations as before but this time we did this for some of the swear words categories.

\begin{figure*}
\includegraphics[width=\linewidth]{plots/correlation_time_categories}
\caption{Correlation between song offensiveness and popularity over time for different swear words categories}
\label{correlation_time_categories}
\end{figure*}

Again, we see the same trend as before. The plot has many colors but it is not so annoying since we clearly see that all curves (for all swear word categories) follow the same trends: they are very high in the first few years and then they tend to 0. We might be tempted to think that, for music in the mid-10th century, popularity is more correlated with offensiveness because of the Second World War but this is probably wrong. In the following we will see that we have very little data for those years; this leads to very strong correlations as soon as one song has one swear word. It is to be noted that our algorithms sometimes make mistakes because of the lyrics data we are provided with. We will see an example where the lyrics contain the words Whoo - hoo which doesn't mean anything but MusixMatch put the "hoo" as "ho", which is a swear word in our data.

\subsection{Data visualization}
Everything we did until now seems to show that there is no linear dependency for our data. 
But this does not mean there is no dependency at all. 
Another useful method to get better insights about data is to visualize it. 
We use a variety of scatter plots to search for structure in the data.
While this can help to show patterns, we would like to emphasize that the plots don't give any intuition for the actual density of the points.
The plots are figure \ref{scatter_plots}.

\begin{figure*}
\begin{subfigure}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{plots/scatter_off_time}
\caption{Offensiveness over time}
\label{scatter_off_time}
\end{subfigure}
\quad
\begin{subfigure}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{plots/scatter_off_counts}
\caption{Play counts vs offensiveness}
\label{scatter_off_counts}
\end{subfigure}

\centering
\begin{subfigure}[b]{0.45\textwidth}
\centering

\includegraphics[width=\textwidth]{plots/scatter_off_hotness}
\caption{Popularity vs offensiveness}
\label{scatter_off_hotness}
\end{subfigure}
\caption{Scatter plots}
\label{scatter_plots}
\end{figure*}

We show the offensiveness compared to time (on figure \ref{scatter_off_time}), to play counts(on figure \ref{scatter_off_counts}) and to popularity/hotness (on figure \ref{scatter_off_hotness}). The median of absolute offensiveness is $2$ so we decided to also try to plot the same graphs for songs with 2 or more swear words on figure \ref{scatter_plots_2}. 

\begin{figure*}
\begin{subfigure}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{plots/scatter_off_time_2}
\caption{Offensiveness over time}
\label{scatter_off_time_2}
\end{subfigure}
\quad
\begin{subfigure}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{plots/scatter_off_counts_2}
\caption{Play counts vs offensiveness}
\label{scatter_off_counts_2}
\end{subfigure}

\centering
\begin{subfigure}[b]{0.45\textwidth}
\centering

\includegraphics[width=\textwidth]{plots/scatter_off_hotness_2}
\caption{Popularity vs offensiveness}
\label{scatter_off_hotness_2}
\end{subfigure}
\caption{Scatter plots for songs with 2 or more offensive words}
\label{scatter_plots_2}
\end{figure*}

There is not much difference between the 2 scatter plots groups but we can see some structure in the data. First, we see that offensiveness increases over time. The most offensive period in music history is probably located in the last decade of the 20th century but it seems to decrease a little after that. As for the play counts, we can note that the songs which are the most listened to are in general not offensive and that play counts seem to decrease with offensiveness. But the most interesting plot is the hotness one on figures \ref{scatter_off_hotness} and \ref{scatter_off_hotness_2}. It shows that the average hotness songs tend to be more offensive than the others. We see this kind of vertical gaussian shape which seems to culminate somewhere around hotness $0.55$. The trends we observe are driven by a small subset of data points but the mass in center is useless. 


\subsection{Ratio approach}
In this section we introduce a new metric for analysing offensiveness over time: the ratio of offensive songs for a given year. We simply count all the offensive songs and divide it by the total number of song for that year. Our results are shown on figure \ref{ratio_time}. Of course we have to specify what it means for a song to be offensive. In our plots we simply put a threshold on the number of offensive words. On figure \ref{ratio_time} the threshold is $1$ so any song which contains at least one swear word will be considered as offensive. However, we try to vary that threshold and we show more general results on figure \ref{ratio_time_threshold}.

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{plots/ratio_time}
\caption{Ratio of offensive songs over time (threshold = 1)}
\label{ratio_time}
\end{figure*}

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{plots/ratio_time_threshold}
\caption{Ratio of offensive songs over time (higher thresholds)}
\label{ratio_time_threshold}
\end{figure*}

All the threshold seem to lead to a similar conclusion: the offensiveness trends start to spike in the 1990-2000 decade and then decrease when we enter the 21st century. They are nevertheless "kept alive" for a few more years after 2000 before starting to fade. This confirms our intuition from the scatter plots about offensiveness over time.

\subsection{Number of swear words approach}
Now what if we try to simply plot the number of offensive words without taking the songs themselves into account. We simply take all the lyrics for a given year, count the swear words and keep that result. You can observe what we obtain on figure \ref{nb_words}. Of course this is not the right measure since the number of total songs is varying over time so we show the average number of swear words per song on figure \ref{nb_words_avg}

\begin{figure*}
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{plots/nb_words}
\caption{Overall}
\label{nb_words}
\end{subfigure}
\quad
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{plots/nb_words_avg}
\caption{On average per song}
\label{nb_words_avg}
\end{subfigure}
\caption{Number of swear words}
\end{figure*}

Again, we are in the same situation as before: the offensiveness spikes in the last decade of the 20th century and then slowly starts to decrease after the year 2000. Do not be confused by the sudden spike in the year 1956. Actually it is due to a "bug" in the lyrics data. There are 12 songs for that year in our dataset and one of them, "Smokestack Lightning" by Howlin'Wolf, apparently contains 11 swear words. But if we look at the lyrics we see that there are absolutely no swear words in that song. The problem is that the chorus contains the onomatopeia "Whoo hooo" which doesn't mean anything by itself but was recorded by MusixMatch as the word "ho" which is a swear word !

In order to have better insights we show the most offensive songs in our dataset in table \ref{most_offensive_songs}. As we see we have some problems with the data since quite a small sample of these(half of them) has valid year and hotness attributes, which may be a reason why we did not obtain more interesting correlations. Anyway, it is interesting to note that our intuitions from before are confirmed even more now: the 1990-2000 decade is the most offensive period in terms of music. Even the ones for which we do not have the year seem to belong to that decade. If we look up on the Internet, we see that the most offensive one "Don't Gimme No H.A.N./?" was released in 1997. As for the popularity unfortunately our intuition that there is no correlation between popularity and offensiveness also seems to be confirmed. In this sample we mostly have songs of average hotness. Two of them ("Gangster Tripping" and "Acid 8000") seem to be more popular but they are balanced by the below-average ones: "Down For My N's" and "Booty Man (Remix)".

\begin{figure*}
\centering
\input{tables/most_offensive_songs}
\caption{Most offensive songs}
\label{most_offensive_songs}
\end{figure*}

\subsection{Machine learning approach}

Since there seems to be no linear correlation in our data we wanted to try a multilayer perceptron which could potentially have more power and discover structure and non-linear correlations. We used the python keras library and constructed a simple neural network with 4 layers: one input activation and three dense layers. The loss function is the classical mean squared error function and we used the adam optimizer. You can have a look at our notebook if you want to have more details. We used the year and the play counts as features and the offensiveness as labels. We smoothed the offensiveness using a logarithm so that we can make an easier distinction between high and low values. We also smoothed the play counts and mapped them to a range between $0$ and $1$ (we also mapped the years to a range between $0$ and $1$ where $0$ corresponds to $1927$ and $1$ to $2010$ just to have a nicer time feature). We show the results on figure \ref{ml_off_time_pop}.

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{plots/ml_off_time_pop}
\caption{Offensiveness with popularity and time: machine learning approach}
\label{ml_off_time_pop}
\end{figure*}

As we can see, this approach still confirms the idea that songs were the most offensive in the 1990-2000 decade and that they became less vulgar after that. There still seems to be no or little dependency between popularity and offensiveness.

\section{Problems with the Datasets}
We do seem some structure over time, but there doesn't seem to be a strong relationship between popularity and offensiveness.
No result might also be a result, it is possible that our reseach simply affirms that offensiveness doesn't help to make a song more (or less) popular.
But in our research we have found a few datapoints that lead us to believe that our datasets are not good enough.
To provide an example, we have filtered the songs by the total number of swearwords and are looking at the 10 most offensive songs.
From these 10 songs:
\begin{itemize}
  \item 2 have a hotness of NaN
  \item 4 have 0 as year of release
  \item the playcounts are highly questionable
\end{itemize}
Together the first two points remove 5 of the 10 songs. We have no workaround for the year of release, but the hotness can be replaced by the playcounts.\\
We take a closer look at the two songs "Bitch Niggas" and "Gangster Tripping". According to the tasteprofile "Gangster Tripping" has been played a total of 3326 times.
"Bitch Niggas" has only a playcount of 58. Which is surprising since "Bitch Niggas" is a collaboration between "Dr. Dre", "Snoop Dog" and "Mel Man", at least two of them are very popular.
"Gangster Tripping" has been released by "Fat Boy Slim". We have searched for the songs on youtube, their view counts are similar, it seems as if "Bitch Niggas" is a little more popular on youtube.
However, the playcounts record a much higher popularity for "Gangster Tripping".\\
We are aware that such a cursory analysis is probably not representative of the entire dataset.
However we do think that this warrants a new strategy and the search for alternative approaches.

\section{Results}
The correlation between offensiveness and popularity does not seem to exist. There is some structure for some of the songs but, in general, offensiveness seems to have little impact on popularity. There are some very popular and offensive songs as there are some which are very vulgar and unpopular. It does not even seem to exist over time or for the different swear words categories. The main result we get is that the offensiveness was on its peak in the last decade of the 20th century. This result is consistent throughout our different analysis methods. It is not really a suprise since we know that period was well known for the violence in the US "ghettos" where shootings were very common and rap music full of offensive words was very popular. However, probably we could find more interesting insights if we had better data.

\section{Outview}
In this outview we present alternative data sources that could be used to continue our research on the topic of music offensiveness and popularity.

\subsection{Youtube view count as popularity measure}
The main problem is that Youtube was founded in 2005 so we would have no data for music before that
year. This would leave us with a lot of songs we can’t even talk about. And, since one of the core ideas of
our project is to do our analysis based on time (compute the correlations between offensiveness and
popularity over time), this would have left us with only a few years between 2005 and 2010 (the data
stops at 2011), which is probably not enough to do get interesting data. Another issue tightly related to
this one is that the popularity of Youtube itself is variable. For example « Despacito » is the most viewed
video on Youtube today with over 4.5 billion views but, 7 years ago, it was Justin Bieber’s « Baby » with
only 1.7 billion views. It’s probably not that « Despacito » is 2.6 times more popular than « Baby » was
but just that Youtube was not used as much as it is used today. A lot less people had a connection to the
Internet and there were also other means of listening to music (there are also other means today but they
are not the same as before). Simply said, there is a variable we might call « Youtube usage » (or poularity
or acces – you can call it however you want) which varies over time and we would have to scale the
number of views according to this variable, which is quite difficult or maybe even non feasible.


One other problem is the way data is structured on Youtube. The way we would gather our info would be
to simply try to match the names of our songs with the name on Youtube since the track id used in the
Million Songs dataset simply doesn’t exist on Youtube. But, however, we know there can be many videos
for one song. We often have the official video and additional videos with lyrics posted by fans (and there
can be many of them). So the total number of views is scattered all around and we have no way to find a
guarantee that what we are scraping is enough. We might take only official videos but even that is not
such a good idea because we would probably lose a lot of info and we would also fall for fake official
videos. And the view count is not a good measure because a video can be removed and reuploaded
because of artist rights or other things.

\subsection{Spotify}
One other idea we had in mind was to use the Spotify API. Spotify is one of the most
popular apps today for listening to music so it can probably be used to gather interesting information. The
Spotify API is very complete since it provides us with all the values we would need in our analysis,
especially with the track info such as play counts for users or popularity. However, this popularity
attribute seems to vary over time because the documentation specifies that a song which has more play
counts now will have a better popularity than a song which has the same number of play counts in the
past. We might still use the play count or other attributes in our analysis so it would probably give some
interesting results. However, the effort to put in is too high because the process for registering an app for
being able to use that API seems to be quite long. It is probable that this method would not give better
results than the hotness/playcounts analysis we already did. But it might be interesting for some future
work.

\subsection{Internet for the release year}
One of the main problems of our dataset is also that the year of realease is missing for a lot of songs. We believe this had a significant impact on our results. However, we can easily find the release year by searching the songs on Google. So one possibility might be to build a scraping system which would find the missing years. For example, it could do the search on Google, visit the sites and do natural language processing in order to find it. However, it is obvious that this strategy would be very difficult and time-consuming to set up. There would probably be a lot of exceptions where it would not work. The amount of effort and time put into this type of approach would probably not be worth the results. 

\begin{thebibliography}{}

  
\bibitem[\protect\citename{MSD}]{MSD}
\newblock {\em Million Song Dataset}
\newblock MSD
\newblock https://labrosa.ee.columbia.edu/millionsong/

\bibitem[\protect\citename{MusixMatch}]{MusixMatch}
MusixMatch Dataset, https://labrosa.ee.columbia.edu/millionsong/musixmatch

\bibitem[\protect\citename{Aho and Ullman}1972]{Aho:72}
Alfred~V. Aho and Jeffrey~D. Ullman.
\newblock 1972.
\newblock {\em The Theory of Parsing, Translation and Compiling}, volume~1.
\newblock Prentice-{Hall}, Englewood Cliffs, NJ.

\bibitem[\protect\citename{{American Psychological Association}}1983]{APA:83}
{American Psychological Association}.
\newblock 1983.
\newblock {\em Publications Manual}.
\newblock American Psychological Association, Washington, DC.

\bibitem[\protect\citename{{Association for Computing Machinery}}1983]{ACM:83}
{Association for Computing Machinery}.
\newblock 1983.
\newblock {\em Computing Reviews}, 24(11):503--512.

\bibitem[\protect\citename{Chandra \bgroup et al.\egroup }1981]{Chandra:81}
Ashok~K. Chandra, Dexter~C. Kozen, and Larry~J. Stockmeyer.
\newblock 1981.
\newblock Alternation.
\newblock {\em Journal of the Association for Computing Machinery},
  28(1):114--133.

\bibitem[\protect\citename{Gusfield}1997]{Gusfield:97}
Dan Gusfield.
\newblock 1997.
\newblock {\em Algorithms on Strings, Trees and Sequences}.
\newblock Cambridge University Press, Cambridge, UK.

\end{thebibliography}

\end{document}

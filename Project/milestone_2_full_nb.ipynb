{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the offensiveness of a song\n",
    "\n",
    "First things first, the most important thing we want to have for our project is a way to measure the offensiveness of a song. We will do this by counting the number of offensive words in a song. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Dataframe for the rating of offensiveness\n",
    "I'm using a paper released by the British telecommunications regulator Ofcom: https://www.ofcom.org.uk/__data/assets/pdf_file/0023/91625/OfcomQRG-AOC.pdf\n",
    "\n",
    "There is a useful transcription here:\n",
    "http://metro.co.uk/2016/10/02/swearing-ranked-from-mild-to-strongest-6165629/#\n",
    "\n",
    "I created a JSON file from the data of that website.\n",
    "This notebook will load this file and convert it to a Dataframe with a usable layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fenian', 'Kafir', 'Kufaar', 'Kike', 'Papist', 'Prod', 'Taig', 'Yid']\n",
      "['Kraut', 'Pikey', 'Taff']\n",
      "['Arse', 'Bloody', 'Bugger', 'Cow', 'Crap', 'Damn', 'Ginger', 'Git', 'God', 'Goddam', 'Jesus Christ', 'Minger', 'Sod-off']\n"
     ]
    }
   ],
   "source": [
    "with open(\"../datasets/metro_co_uk_transcription.json\") as file:\n",
    "    offensiveness_rating = json.load(file)\n",
    "    \n",
    "# the offensiveness rating is a nested JSON file\n",
    "# after three levels of json objects, there is a list of words\n",
    "# it looks like this:\n",
    "print(offensiveness_rating[\"discriminatory\"][\"religion\"][\"strong\"])\n",
    "print(offensiveness_rating[\"discriminatory\"][\"race\"][\"medium\"])\n",
    "\n",
    "# there are also offensive words that are not discriminating\n",
    "# for them, the second key doesn't really make sense, I just entered \"offensive\"\n",
    "print(offensiveness_rating[\"non-discriminatory\"][\"offensive\"][\"mild\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for further processing, we want to have a dataframe with the words as index\n",
    "# a cell in the dataframe should be a word and the rating of offensiveness\n",
    "# if the word is discriminating, we also want to have the target group\n",
    "\n",
    "entries = []\n",
    "\n",
    "def clean(word):\n",
    "    return word.strip().lower()\n",
    "\n",
    "# words are always three levels down in the file\n",
    "for category, value in offensiveness_rating.items():\n",
    "    for target, value in value.items():\n",
    "        for strength, words in value.items():\n",
    "            for word in words:\n",
    "                entry = {}\n",
    "                entry[\"category\"] = clean(category)\n",
    "                entry[\"word\"] = clean(word)\n",
    "                entry[\"strength\"] = clean(strength)\n",
    "                \n",
    "                assert category in [\"discriminatory\", \"non-discriminatory\"]\n",
    "                \n",
    "                if category==\"discriminatory\":\n",
    "                    entry[\"target\"] = clean(target)\n",
    "                else:\n",
    "                    entry[\"target\"] = None\n",
    "                \n",
    "                entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'non-discriminatory',\n",
       "  'strength': 'mild',\n",
       "  'target': None,\n",
       "  'word': 'bonk'},\n",
       " {'category': 'non-discriminatory',\n",
       "  'strength': 'strong',\n",
       "  'target': None,\n",
       "  'word': 'bukkake'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>mild</td>\n",
       "      <td>None</td>\n",
       "      <td>bonk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "      <td>bukkake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "      <td>cocksucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "      <td>dildo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "      <td>ho</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category strength target        word\n",
       "0  non-discriminatory     mild   None        bonk\n",
       "1  non-discriminatory   strong   None     bukkake\n",
       "2  non-discriminatory   strong   None  cocksucker\n",
       "3  non-discriminatory   strong   None       dildo\n",
       "4  non-discriminatory   strong   None          ho"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table = pd.DataFrame(entries)\n",
    "word_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonk</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>mild</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bukkake</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocksucker</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dildo</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ho</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category strength target\n",
       "word                                          \n",
       "bonk        non-discriminatory     mild   None\n",
       "bukkake     non-discriminatory   strong   None\n",
       "cocksucker  non-discriminatory   strong   None\n",
       "dildo       non-discriminatory   strong   None\n",
       "ho          non-discriminatory   strong   None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table= word_table.set_index(\"word\")\n",
    "word_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_table.to_pickle(\"../pickles/word_table.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking our list of swearwords\n",
    "\n",
    "The musixmatch database contains lyrics for a selection of tracks from the million-song-database.\n",
    "\n",
    "But the lyrics are only given by wordcount. So for any given song, we don't have the actual text, but only the number of times that the singer has said \"I\" or \"you\".\n",
    "\n",
    "This makes the rating of offensiveness much harder, since we lose all context.\n",
    "For example: \"Jesus Christ\" and \"god\" are rated as mildly offensive and non-discriminatory. If you use them as expletive, that might be correct. But we still don't want to classify gospel songs as outliers with a high frequency of mild swearing.\n",
    "\n",
    "In this notebook we load all words that are present in the lyrics and check which of them are covered in our list of swearwords.\n",
    "Then we go through the lyrics again, to check if our swearwords are missing something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../datasets/mxm_dataset.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('words',), ('lyrics',)]\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i',), ('the',), ('you',), ('to',), ('and',)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * FROM words;\")\n",
    "words = cursor.fetchall()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonk</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>mild</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bukkake</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocksucker</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dildo</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ho</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category strength target\n",
       "word                                          \n",
       "bonk        non-discriminatory     mild   None\n",
       "bukkake     non-discriminatory   strong   None\n",
       "cocksucker  non-discriminatory   strong   None\n",
       "dildo       non-discriminatory   strong   None\n",
       "ho          non-discriminatory   strong   None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table = pd.read_pickle(\"../pickles/word_table.pickle\")\n",
    "word_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('god',)\n",
      "('fuck',)\n",
      "('shit',)\n",
      "('damn',)\n",
      "('ho',)\n",
      "('bitch',)\n",
      "('special',)\n",
      "('dick',)\n",
      "('whore',)\n",
      "('mental',)\n",
      "('bastard',)\n",
      "('negro',)\n",
      "('bullshit',)\n",
      "('cock',)\n",
      "('cow',)\n",
      "('slut',)\n",
      "('psycho',)\n",
      "('cunt',)\n",
      "('crap',)\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word[0] in word_table.index:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I read all the words in the database\n",
    "# this is a manual list of swearwords\n",
    "# please note that I'm not a native speaker, it is possible that I've missed something\n",
    "\n",
    "# this is a list of words that are with very high likelihood used as swearwords,\n",
    "# or that are obviously obscene.\n",
    "offensive_list = [\"fuck\", \"fool\", \"shit\", \"nigga\", \"damn\", \"bitch\", \"ass\", \"fuckin\", \"freak\", \"motherfuck\", \"rape\", \"dick\", \"whore\", \"bastard\", \"sucker\", \"pussi\",\n",
    "\"bum\", \"gay\", \"cock\", \"jerk\", \"cunt\", \"junk\", \"motherfuckin\", \"crap\"]\n",
    "         \n",
    "# the second list of words is colloquial\n",
    "# they might be offensive, but it's not really clear without context\n",
    "colloquial_list = [\"trippin\",\"thug\",\"gangsta\",\"gypsi\",\"booti\",\"junki\",\"shorti\"]\n",
    "                  \n",
    "# then we have a third list\n",
    "# I've only filled this with exemplary samples\n",
    "# the third list contains very negative words\n",
    "# but these words are not offensive\n",
    "negative_list = [\"slave\",\" satan\",\"suicid\",\"cocain\",\"genocid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the swearwords\n",
    "\n",
    "Based on the data above, we have to clear our list of swearwords.\n",
    "We remove\n",
    " - negro, because that is probably just Spanish\n",
    " - god, because this is only offensive in context\n",
    " \n",
    "The words found above, that are not in the list of swearwords will be added based on their similarity to existing words.\n",
    "For most additions, the choice of strength and category seems easy. Here is a list of choices that might be discussed:\n",
    "\n",
    "- \"freak\", similar to \"retard\" or \"spastic\"\n",
    "- \"jerk\", similar to \"bastard\"\n",
    "- \"booti\", similar to \"arse\"\n",
    "\n",
    "We also add some words from the colloquial list\n",
    " - gypsi\n",
    " - shorti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_table = word_table.drop(\"negro\")\n",
    "word_table = word_table.drop(\"god\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fuck exists\n",
    "\n",
    "# we add fool, similar to \"loony\", \"mental\" \n",
    "word_table.loc[\"fool\"]={\"category\":\"discriminatory\", \"strength\":\"mild\", \"target\":\"mental or physical ability\"}\n",
    "\n",
    "# shit exists\n",
    "\n",
    "# we add nigga, similar to nigger\n",
    "word_table.loc[\"nigga\"]={\"category\":\"discriminatory\", \"strength\":\"strongest\", \"target\":\"race\"}\n",
    "\n",
    "# damn exists\n",
    "# bitch exists\n",
    "\n",
    "# we add ass, similar to arse\n",
    "word_table.loc[\"ass\"]={\"category\":\"non-discriminatory\", \"strength\":\"mild\", \"target\":None}\n",
    "\n",
    "# we add fuckin, similar to fuck\n",
    "word_table.loc[\"fuckin\"]={\"category\":\"non-discriminatory\", \"strength\":\"strongest\", \"target\":None}\n",
    "\n",
    "# we add freak, similar to retard\n",
    "word_table.loc[\"freak\"]={\"category\":\"discriminatory\", \"strength\":\"strongest\", \"target\":\"mental or physical ability\"}\n",
    "\n",
    "# we add motherfuck and motherfuckin, similar to motherfucker\n",
    "word_table.loc[\"motherfuck\"]={\"category\":\"non-discriminatory\", \"strength\":\"strongest\", \"target\":None}\n",
    "word_table.loc[\"motherfuckin\"]={\"category\":\"non-discriminatory\", \"strength\":\"strongest\", \"target\":None}\n",
    "\n",
    "# we add rape, similar to rapey\n",
    "word_table.loc[\"rape\"]={\"category\":\"non-discriminatory\", \"strength\":\"strongest\", \"target\":None}\n",
    "\n",
    "# dick already exists\n",
    "# whore already exists\n",
    "\n",
    "\n",
    "# we add bum, similar to arse\n",
    "word_table.loc[\"bum\"]={\"category\":\"non-discriminatory\", \"strength\":\"mild\", \"target\":None}\n",
    "\n",
    "# we add gay, similar to homo\n",
    "word_table.loc[\"gay\"]={\"category\":\"discriminatory\", \"strength\":\"strong\", \"target\":\"sexuality\"}\n",
    "\n",
    "# we add cock, similar to dick\n",
    "word_table.loc[\"cock\"]={\"category\":\"non-discriminatory\", \"strength\":\"strong\", \"target\":None}\n",
    "\n",
    "# we add jerk, similar to bastard\n",
    "word_table.loc[\"jerk\"]={\"category\":\"non-discriminatory\", \"strength\":\"strong\", \"target\":None}\n",
    "\n",
    "# we add junk, similar to Crap\n",
    "word_table.loc[\"junk\"]={\"category\":\"non-discriminatory\", \"strength\":\"mild\", \"target\":None}\n",
    "\n",
    "# we add booty, similar to arse\n",
    "word_table.loc[\"booti\"]={\"category\":\"non-discriminatory\", \"strength\":\"mild\", \"target\":None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we add shorti, mildly discriminative against women\n",
    "word_table.loc[\"shorti\"]={\"category\":\"discriminatory\", \"strength\":\"mild\", \"target\":\"sexuality\"}\n",
    "\n",
    "# we add gypsi, medium discriminative against gypsies\n",
    "word_table.loc[\"gypsi\"]={\"category\":\"discriminatory\", \"strength\":\"medium\", \"target\":\"race\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking occurence of words again\n",
    "We go through all words that occur in the lyrics and check against our list of swearwords.\n",
    "The resulting list should only contain words that are obviously swearwords.\n",
    "\n",
    "We save the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fuck',)\n",
      "('fool',)\n",
      "('shit',)\n",
      "('nigga',)\n",
      "('damn',)\n",
      "('ho',)\n",
      "('bitch',)\n",
      "('ass',)\n",
      "('special',)\n",
      "('fuckin',)\n",
      "('freak',)\n",
      "('motherfuck',)\n",
      "('rape',)\n",
      "('dick',)\n",
      "('whore',)\n",
      "('mental',)\n",
      "('bastard',)\n",
      "('bum',)\n",
      "('bullshit',)\n",
      "('gay',)\n",
      "('cock',)\n",
      "('gypsi',)\n",
      "('cow',)\n",
      "('jerk',)\n",
      "('booti',)\n",
      "('shorti',)\n",
      "('slut',)\n",
      "('psycho',)\n",
      "('cunt',)\n",
      "('junk',)\n",
      "('motherfuckin',)\n",
      "('crap',)\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word[0] in word_table.index:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_table.to_pickle(\"../pickles/word_table_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating a song in the msd database (obsolete)\n",
    "This was a first attempt to rate the offensiveness of a song in the database.\n",
    "To do this, we need to\n",
    "- identify an individual song\n",
    "- get all lyrics corresponding to this song\n",
    "- rate them by offensiveness\n",
    "\n",
    "In this notebook, we are investigating the structure of the data.\n",
    "But our approach is not fast enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../datasets/mxm_dataset.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database contains the following:\n",
    "\n",
    "https://github.com/tbertinmahieux/MSongsDB/blob/master/Tasks_Demos/Lyrics/README.txt\n",
    "_More details on the database:\n",
    "   - it contains two tables, 'words' and 'lyrics'\n",
    "   - table 'words' has one column: 'word'. Words are entered according\n",
    "     to popularity, check their ROWID if you want to check their position.\n",
    "     ROWID is an implicit column in SQLite, it starts at 1.\n",
    "   - table 'lyrics' contains 5 columns, see below\n",
    "   - column 'track_id' -> as usual, track id from the MSD\n",
    "   - column 'mxm_tid' -> track ID from musiXmatch\n",
    "   - column 'word' -> a word that is also in the 'words' table\n",
    "   - column 'cnt' -> word count for the word\n",
    "   - column 'is_test' -> 0 if this example is from the train set, 1 if test_\n",
    "   \n",
    "We want to connect our insights to the million song database and its metadata.\n",
    "Therefore we want to use the track_id to identify songs.\n",
    "\n",
    "The lyrics table contains individual entries for every "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'track_id', '', 0, None, 0), (1, 'mxm_tid', 'INT', 0, None, 0), (2, 'word', 'TEXT', 0, None, 0), (3, 'count', 'INT', 0, None, 0), (4, 'is_test', 'INT', 0, None, 0)]\n"
     ]
    }
   ],
   "source": [
    "# this is the content of the lyrics table\n",
    "# please note that it's not \"cnt\" but \"count\", the README is wrong\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"PRAGMA table_info(lyrics);\")\n",
    "print(cursor.fetchall())\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SQL to extract information\n",
    "\n",
    "We want to have all track ids, and for every track id, we need the words and counts\n",
    "\n",
    "The data is big, but even as a pandas DataFrame, the size stays below 5GB.\n",
    "I think the comfort of pandas is enough to warrant loading this into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TRAAAAV128F421A322',),\n",
       " ('TRAAABD128F429CF47',),\n",
       " ('TRAAAED128E0783FAB',),\n",
       " ('TRAAAEF128F4273421',),\n",
       " ('TRAAAEW128F42930C0',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT DISTINCT track_id FROM lyrics ORDER BY track_id;\")\n",
    "track_ids = cursor.fetchall()\n",
    "cursor.close()\n",
    "track_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TRAAAAV128F421A322', 'i', 6),\n",
       " ('TRAAAAV128F421A322', 'the', 4),\n",
       " ('TRAAAAV128F421A322', 'you', 2),\n",
       " ('TRAAAAV128F421A322', 'to', 2),\n",
       " ('TRAAAAV128F421A322', 'and', 5)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT track_id, word, count FROM lyrics ORDER BY track_id;\")\n",
    "track_word_count = cursor.fetchall()\n",
    "cursor.close()\n",
    "track_word_count[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TRAAAAV128F421A322',),\n",
       " ('TRAAABD128F429CF47',),\n",
       " ('TRAAAED128E0783FAB',),\n",
       " ('TRAAAEF128F4273421',),\n",
       " ('TRAAAEW128F42930C0',)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_series = pd.Series(track_ids)\n",
    "track_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqldb_frame = pd.DataFrame(track_word_count, columns=[\"track_id\", \"word\", \"count\"])\n",
    "del track_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a table to hold song ratings\n",
    "\n",
    "We want to create a table which allows intuitive indexing into the rating of a song.\n",
    "\n",
    "The table will contain the frequency of each word category. We set up a multiindex to allow slicing along the different characteristics of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_table = pd.read_pickle(\"../pickles/word_table_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonk</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>mild</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bukkake</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocksucker</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dildo</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ho</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category strength target\n",
       "word                                          \n",
       "bonk        non-discriminatory     mild   None\n",
       "bukkake     non-discriminatory   strong   None\n",
       "cocksucker  non-discriminatory   strong   None\n",
       "dildo       non-discriminatory   strong   None\n",
       "ho          non-discriminatory   strong   None"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_tuples=[]\n",
    "\n",
    "for strength in [\"mild\", \"medium\", \"strong\", \"strongest\"]:\n",
    "    for category in [\"discriminatory\", \"non-discriminatory\"]:\n",
    "        for target in [\"None\", \"race\", \"mental or physical ability\", \"sexuality\"]:\n",
    "            index_tuples.append([strength, category, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(index_tuples, names=[\"strength\", \"category\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_frame = pd.DataFrame(index=[\"track_id\"], columns = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>strength</th>\n",
       "      <th colspan=\"8\" halign=\"left\">mild</th>\n",
       "      <th colspan=\"2\" halign=\"left\">medium</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">strong</th>\n",
       "      <th colspan=\"8\" halign=\"left\">strongest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th colspan=\"4\" halign=\"left\">discriminatory</th>\n",
       "      <th colspan=\"4\" halign=\"left\">non-discriminatory</th>\n",
       "      <th colspan=\"2\" halign=\"left\">discriminatory</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">non-discriminatory</th>\n",
       "      <th colspan=\"4\" halign=\"left\">discriminatory</th>\n",
       "      <th colspan=\"4\" halign=\"left\">non-discriminatory</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th>None</th>\n",
       "      <th>race</th>\n",
       "      <th>mental or physical ability</th>\n",
       "      <th>sexuality</th>\n",
       "      <th>None</th>\n",
       "      <th>race</th>\n",
       "      <th>mental or physical ability</th>\n",
       "      <th>sexuality</th>\n",
       "      <th>None</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>mental or physical ability</th>\n",
       "      <th>sexuality</th>\n",
       "      <th>None</th>\n",
       "      <th>race</th>\n",
       "      <th>mental or physical ability</th>\n",
       "      <th>sexuality</th>\n",
       "      <th>None</th>\n",
       "      <th>race</th>\n",
       "      <th>mental or physical ability</th>\n",
       "      <th>sexuality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "strength           mild                                            \\\n",
       "category discriminatory                                             \n",
       "target             None race mental or physical ability sexuality   \n",
       "track_id            NaN  NaN                        NaN       NaN   \n",
       "\n",
       "strength                                                               \\\n",
       "category non-discriminatory                                             \n",
       "target                 None race mental or physical ability sexuality   \n",
       "track_id                NaN  NaN                        NaN       NaN   \n",
       "\n",
       "strength         medium         ...                        strong            \\\n",
       "category discriminatory         ...            non-discriminatory             \n",
       "target             None race    ...    mental or physical ability sexuality   \n",
       "track_id            NaN  NaN    ...                           NaN       NaN   \n",
       "\n",
       "strength      strongest                                            \\\n",
       "category discriminatory                                             \n",
       "target             None race mental or physical ability sexuality   \n",
       "track_id            NaN  NaN                        NaN       NaN   \n",
       "\n",
       "strength                                                               \n",
       "category non-discriminatory                                            \n",
       "target                 None race mental or physical ability sexuality  \n",
       "track_id                NaN  NaN                        NaN       NaN  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the rating frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's look at a sample song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRAAAAV128F421A322',)\n"
     ]
    }
   ],
   "source": [
    "for track_id in id_series:\n",
    "    print(track_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mentioned_words = sqldb_frame[sqldb_frame[\"track_id\"]==track_id[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('mild', 'non-discriminatory', 'None'): 0.009708737864077669}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_entry(mentioned_words):\n",
    "\n",
    "    entry = {}\n",
    "    total_count = 0\n",
    "\n",
    "    for index, row in mentioned_words.iterrows():\n",
    "        word = row[\"word\"]\n",
    "        count = row[\"count\"]\n",
    "        total_count+=count\n",
    "\n",
    "        if word in word_table.index:\n",
    "            rating = word_table.loc[word]\n",
    "            strength = rating[\"strength\"]\n",
    "            category = rating[\"category\"]\n",
    "            target = rating[\"target\"]\n",
    "\n",
    "            if target==None:\n",
    "                target=\"None\"\n",
    "            \n",
    "            index = (strength, category, target)\n",
    "            if index in entry:\n",
    "                entry[index] += count\n",
    "            else:\n",
    "                entry[index] = count\n",
    "                \n",
    "    if total_count >0:\n",
    "        normalized={}\n",
    "        for key, value in entry.items():\n",
    "            normalized[key] = value / total_count\n",
    "\n",
    "\n",
    "        return normalized\n",
    "    else:\n",
    "        return entry\n",
    "\n",
    "fill_entry(mentioned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add all songs to the rating_frame\n",
    "This takes much too long.\n",
    "\n",
    "The hotspot is searching for the words in this track.\n",
    "Maybe we can have a group by or something similar before this ?\n",
    "\n",
    "Or we need to run this on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/237662 [00:48<72:03:02,  1.09s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ede5629d2764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrack_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrack_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrack_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmentioned_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqldb_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msqldb_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"track_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtrack_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmentioned_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for track_id in tqdm(id_series):\n",
    "    track_id = track_id[0]\n",
    "    mentioned_words = sqldb_frame[sqldb_frame[\"track_id\"]==track_id]\n",
    "    entry = fill_entry(mentioned_words)\n",
    "    \n",
    "    if entry == None:\n",
    "        print(\"bad: \"+track_id)\n",
    "    else:\n",
    "        rating_frame.loc[track_id, :]=entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were obliged to interrupt this process because it is waaay too long. So we will find another way to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructure our table\n",
    "\n",
    "We flatten the table of offensive words. This means that we can now use it in combination with technologies such as spark - that don't support multiindex structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table = pd.read_pickle(\"../pickles/word_table_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonk</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>mild</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bukkake</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocksucker</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dildo</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ho</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category strength target\n",
       "word                                          \n",
       "bonk        non-discriminatory     mild   None\n",
       "bukkake     non-discriminatory   strong   None\n",
       "cocksucker  non-discriminatory   strong   None\n",
       "dildo       non-discriminatory   strong   None\n",
       "ho          non-discriminatory   strong   None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_table[\"descriptor\"] = word_table[[\"category\", \"strength\", \"target\"]].apply(tuple, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "      <th>descriptor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonk</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>mild</td>\n",
       "      <td>None</td>\n",
       "      <td>(non-discriminatory, mild, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bukkake</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "      <td>(non-discriminatory, strong, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocksucker</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "      <td>(non-discriminatory, strong, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dildo</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "      <td>(non-discriminatory, strong, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ho</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "      <td>(non-discriminatory, strong, None)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category strength target  \\\n",
       "word                                             \n",
       "bonk        non-discriminatory     mild   None   \n",
       "bukkake     non-discriminatory   strong   None   \n",
       "cocksucker  non-discriminatory   strong   None   \n",
       "dildo       non-discriminatory   strong   None   \n",
       "ho          non-discriminatory   strong   None   \n",
       "\n",
       "                                    descriptor  \n",
       "word                                            \n",
       "bonk          (non-discriminatory, mild, None)  \n",
       "bukkake     (non-discriminatory, strong, None)  \n",
       "cocksucker  (non-discriminatory, strong, None)  \n",
       "dildo       (non-discriminatory, strong, None)  \n",
       "ho          (non-discriminatory, strong, None)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_table_filtered = word_table[\"descriptor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "bonk            (non-discriminatory, mild, None)\n",
       "bukkake       (non-discriminatory, strong, None)\n",
       "cocksucker    (non-discriminatory, strong, None)\n",
       "dildo         (non-discriminatory, strong, None)\n",
       "ho            (non-discriminatory, strong, None)\n",
       "Name: descriptor, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table_filtered.to_csv(\"../datasets/word_table.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing the computation\n",
    "The loop-based approach to process each track id individually is taking too long.\n",
    "Now we will leverage the data processing capabilities of pandas.\n",
    "\n",
    "We use an outer join to combine lyrics with track ids. Then we aggregate the results for individual songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>descriptor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonk</td>\n",
       "      <td>('non-discriminatory', 'mild', None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bukkake</td>\n",
       "      <td>('non-discriminatory', 'strong', None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cocksucker</td>\n",
       "      <td>('non-discriminatory', 'strong', None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dildo</td>\n",
       "      <td>('non-discriminatory', 'strong', None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ho</td>\n",
       "      <td>('non-discriminatory', 'strong', None)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                              descriptor\n",
       "0        bonk    ('non-discriminatory', 'mild', None)\n",
       "1     bukkake  ('non-discriminatory', 'strong', None)\n",
       "2  cocksucker  ('non-discriminatory', 'strong', None)\n",
       "3       dildo  ('non-discriminatory', 'strong', None)\n",
       "4          ho  ('non-discriminatory', 'strong', None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table = pd.read_csv(\"../datasets/word_table.csv\")\n",
    "word_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "bonk            ('non-discriminatory', 'mild', None)\n",
       "bukkake       ('non-discriminatory', 'strong', None)\n",
       "cocksucker    ('non-discriminatory', 'strong', None)\n",
       "dildo         ('non-discriminatory', 'strong', None)\n",
       "ho            ('non-discriminatory', 'strong', None)\n",
       "Name: descriptor, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table[\"word\"]=word_table[\"word\"].astype(str)\n",
    "word_table.index = word_table[\"word\"]\n",
    "word_table = word_table[\"descriptor\"]\n",
    "word_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TRAAAAV128F421A322', 'i', 6),\n",
       " ('TRAAAAV128F421A322', 'the', 4),\n",
       " ('TRAAAAV128F421A322', 'you', 2),\n",
       " ('TRAAAAV128F421A322', 'to', 2),\n",
       " ('TRAAAAV128F421A322', 'and', 5)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../datasets/mxm_dataset.db\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT track_id, word, count FROM lyrics ORDER BY track_id;\")\n",
    "track_word_count = cursor.fetchall()\n",
    "cursor.close()\n",
    "track_word_count[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqldb_frame = pd.DataFrame(track_word_count, columns=[\"track_id\", \"word\", \"count\"])\n",
    "del track_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqldb_frame[\"word\"]=sqldb_frame[\"word\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing an outer joint to match words between lyrics and offensiveness rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19045332, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>descriptor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>i</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>the</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>you</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>to</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>and</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             track_id word  count descriptor\n",
       "0  TRAAAAV128F421A322    i      6        NaN\n",
       "1  TRAAAAV128F421A322  the      4        NaN\n",
       "2  TRAAAAV128F421A322  you      2        NaN\n",
       "3  TRAAAAV128F421A322   to      2        NaN\n",
       "4  TRAAAAV128F421A322  and      5        NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint = sqldb_frame.join(word_table, on=\"word\", how=\"left\", lsuffix='_caller', rsuffix='_other')\n",
    "print(joint.shape)\n",
    "joint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obscene_indices = joint[\"descriptor\"].astype(\"str\")!=\"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(obscene_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83542"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(obscene_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descriptor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>i</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>the</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>you</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>to</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>and</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>me</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>it</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>not</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>in</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>my</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>is</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>your</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>that</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>do</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>on</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>are</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>we</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>am</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>will</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>all</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>for</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>be</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>so</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>know</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>this</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>walkin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>pound</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>suit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>ima</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('non-discriminatory', 'strongest', None)</th>\n",
       "      <td>motherfuck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>favorit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>toe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>class</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>spot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>playin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>receiv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>coat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>cheek</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>whip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>hop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>chick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>givin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>mist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>team</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>gear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>repres</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>smokin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>ref</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>stroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>butt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('discriminatory', 'mild', 'sexuality')</th>\n",
       "      <td>shorti</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>peep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>boo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 word  count\n",
       "descriptor                                                  \n",
       "NaN                                                 i     16\n",
       "NaN                                               the     26\n",
       "NaN                                               you      6\n",
       "NaN                                                to     13\n",
       "NaN                                               and     29\n",
       "NaN                                                 a      2\n",
       "NaN                                                me      3\n",
       "NaN                                                it      7\n",
       "NaN                                               not      5\n",
       "NaN                                                in      9\n",
       "NaN                                                my     29\n",
       "NaN                                                is     10\n",
       "NaN                                                of      1\n",
       "NaN                                              your      3\n",
       "NaN                                              that      6\n",
       "NaN                                                do     23\n",
       "NaN                                                on      7\n",
       "NaN                                               are      2\n",
       "NaN                                                we     29\n",
       "NaN                                                am      3\n",
       "NaN                                              will      4\n",
       "NaN                                               all     38\n",
       "NaN                                               for      1\n",
       "NaN                                                no      1\n",
       "NaN                                                be      1\n",
       "NaN                                              have      1\n",
       "NaN                                              love      2\n",
       "NaN                                                so      1\n",
       "NaN                                              know      2\n",
       "NaN                                              this     40\n",
       "...                                               ...    ...\n",
       "NaN                                            walkin      1\n",
       "NaN                                             south      1\n",
       "NaN                                             pound      1\n",
       "NaN                                              suit      1\n",
       "NaN                                               ima      1\n",
       "('non-discriminatory', 'strongest', None)  motherfuck      1\n",
       "NaN                                           favorit      1\n",
       "NaN                                               toe      1\n",
       "NaN                                             class      1\n",
       "NaN                                              spot      1\n",
       "NaN                                                 w      3\n",
       "NaN                                            playin      1\n",
       "NaN                                            receiv      1\n",
       "NaN                                              coat      1\n",
       "NaN                                             cheek      7\n",
       "NaN                                              whip      1\n",
       "NaN                                               hop      1\n",
       "NaN                                             chick      1\n",
       "NaN                                             givin      1\n",
       "NaN                                              mist      1\n",
       "NaN                                              team      1\n",
       "NaN                                              gear      1\n",
       "NaN                                            repres      1\n",
       "NaN                                            smokin      1\n",
       "NaN                                               ref      1\n",
       "NaN                                            stroll      1\n",
       "NaN                                              butt      1\n",
       "('discriminatory', 'mild', 'sexuality')        shorti      3\n",
       "NaN                                              peep      1\n",
       "NaN                                               boo      1\n",
       "\n",
       "[197 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_indexed = joint.set_index([\"track_id\", \"descriptor\"])\n",
    "joint_indexed.loc[(\"TRAADYI128E078FB38\",),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the data\n",
    "The joint table uses track ids and offensiveness categories as indices. This is what we want, but we still have individual cells for every word.\n",
    "\n",
    "Now we aggregate the items for every index. We sum the entries. This gives us the total count of words in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_indexed.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id            descriptor\n",
       "TRAAAAV128F421A322  NaN           6\n",
       "                    NaN           4\n",
       "                    NaN           2\n",
       "                    NaN           2\n",
       "                    NaN           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_indexed_filtered = joint_indexed[\"count\"]\n",
    "joint_indexed_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joint_aggregated = joint_indexed_filtered.agg(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offensiveness_rating = joint_indexed_filtered.groupby(str, axis=0).agg(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TRAAAAV128F421A322', \"('non-discriminatory', 'mild', None)\")      1\n",
       "('TRAAAAV128F421A322', nan)                                       102\n",
       "('TRAAABD128F429CF47', nan)                                       226\n",
       "('TRAAAED128E0783FAB', nan)                                       421\n",
       "('TRAAAEF128F4273421', nan)                                       139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offensiveness_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offensiveness_rating.to_pickle(\"../pickles/offensiveness_rating_unstructured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing the computation, 2nd approach\n",
    "\n",
    "In the last notebook we have created a table of track ids and offensiveness.\n",
    "But we have lost the detailed multi-index structure.\n",
    "\n",
    "The flattening is not necessary for pandas outer-join to work.\n",
    "We repeat the procedure and generate a second table which has a deeply nested multiindex.\n",
    "\n",
    "The structure of this subsection is basically identical to the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonk</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>mild</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bukkake</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocksucker</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dildo</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ho</th>\n",
       "      <td>non-discriminatory</td>\n",
       "      <td>strong</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category strength target\n",
       "word                                          \n",
       "bonk        non-discriminatory     mild   None\n",
       "bukkake     non-discriminatory   strong   None\n",
       "cocksucker  non-discriminatory   strong   None\n",
       "dildo       non-discriminatory   strong   None\n",
       "ho          non-discriminatory   strong   None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table = pd.read_pickle(\"../pickles/word_table_cleaned.pickle\")\n",
    "word_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TRAAAAV128F421A322', 'i', 6),\n",
       " ('TRAAAAV128F421A322', 'the', 4),\n",
       " ('TRAAAAV128F421A322', 'you', 2),\n",
       " ('TRAAAAV128F421A322', 'to', 2),\n",
       " ('TRAAAAV128F421A322', 'and', 5)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../datasets/mxm_dataset.db\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT track_id, word, count FROM lyrics ORDER BY track_id;\")\n",
    "track_word_count = cursor.fetchall()\n",
    "cursor.close()\n",
    "track_word_count[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqldb_frame = pd.DataFrame(track_word_count, columns=[\"track_id\", \"word\", \"count\"])\n",
    "del track_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqldb_frame[\"word\"]=sqldb_frame[\"word\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing an outer joint to match words between lyrics and offensiveness rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19045332, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>i</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>the</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>you</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>to</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>and</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             track_id word  count category strength target\n",
       "0  TRAAAAV128F421A322    i      6      NaN      NaN    NaN\n",
       "1  TRAAAAV128F421A322  the      4      NaN      NaN    NaN\n",
       "2  TRAAAAV128F421A322  you      2      NaN      NaN    NaN\n",
       "3  TRAAAAV128F421A322   to      2      NaN      NaN    NaN\n",
       "4  TRAAAAV128F421A322  and      5      NaN      NaN    NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint = sqldb_frame.join(word_table, on=\"word\", how=\"left\", lsuffix='_caller', rsuffix='_other')\n",
    "print(joint.shape)\n",
    "joint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th>strength</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"36\" valign=\"top\">NaN</th>\n",
       "      <th rowspan=\"36\" valign=\"top\">NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>i</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>the</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>you</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>to</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>and</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>me</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>it</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>not</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>in</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>my</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>is</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>your</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>that</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>do</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>on</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>are</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>we</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>am</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>will</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>all</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>for</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>be</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>so</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>know</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>this</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>walkin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>pound</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>suit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>ima</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-discriminatory</th>\n",
       "      <th>strongest</th>\n",
       "      <th>NaN</th>\n",
       "      <td>motherfuck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"21\" valign=\"top\">NaN</th>\n",
       "      <th rowspan=\"21\" valign=\"top\">NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>favorit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>toe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>class</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>spot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>playin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>receiv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>coat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>cheek</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>whip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>hop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>chick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>givin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>mist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>team</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>gear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>repres</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>smokin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>ref</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>stroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>butt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discriminatory</th>\n",
       "      <th>mild</th>\n",
       "      <th>sexuality</th>\n",
       "      <td>shorti</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NaN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>peep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>boo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              word  count\n",
       "category           strength  target                      \n",
       "NaN                NaN       NaN                 i     16\n",
       "                             NaN               the     26\n",
       "                             NaN               you      6\n",
       "                             NaN                to     13\n",
       "                             NaN               and     29\n",
       "                             NaN                 a      2\n",
       "                             NaN                me      3\n",
       "                             NaN                it      7\n",
       "                             NaN               not      5\n",
       "                             NaN                in      9\n",
       "                             NaN                my     29\n",
       "                             NaN                is     10\n",
       "                             NaN                of      1\n",
       "                             NaN              your      3\n",
       "                             NaN              that      6\n",
       "                             NaN                do     23\n",
       "                             NaN                on      7\n",
       "                             NaN               are      2\n",
       "                             NaN                we     29\n",
       "                             NaN                am      3\n",
       "                             NaN              will      4\n",
       "                             NaN               all     38\n",
       "                             NaN               for      1\n",
       "                             NaN                no      1\n",
       "                             NaN                be      1\n",
       "                             NaN              have      1\n",
       "                             NaN              love      2\n",
       "                             NaN                so      1\n",
       "                             NaN              know      2\n",
       "                             NaN              this     40\n",
       "...                                            ...    ...\n",
       "                             NaN            walkin      1\n",
       "                             NaN             south      1\n",
       "                             NaN             pound      1\n",
       "                             NaN              suit      1\n",
       "                             NaN               ima      1\n",
       "non-discriminatory strongest NaN        motherfuck      1\n",
       "NaN                NaN       NaN           favorit      1\n",
       "                             NaN               toe      1\n",
       "                             NaN             class      1\n",
       "                             NaN              spot      1\n",
       "                             NaN                 w      3\n",
       "                             NaN            playin      1\n",
       "                             NaN            receiv      1\n",
       "                             NaN              coat      1\n",
       "                             NaN             cheek      7\n",
       "                             NaN              whip      1\n",
       "                             NaN               hop      1\n",
       "                             NaN             chick      1\n",
       "                             NaN             givin      1\n",
       "                             NaN              mist      1\n",
       "                             NaN              team      1\n",
       "                             NaN              gear      1\n",
       "                             NaN            repres      1\n",
       "                             NaN            smokin      1\n",
       "                             NaN               ref      1\n",
       "                             NaN            stroll      1\n",
       "                             NaN              butt      1\n",
       "discriminatory     mild      sexuality      shorti      3\n",
       "NaN                NaN       NaN              peep      1\n",
       "                             NaN               boo      1\n",
       "\n",
       "[197 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_indexed = joint.set_index([\"track_id\", \"category\", \"strength\", \"target\"])\n",
    "joint_indexed.loc[(\"TRAADYI128E078FB38\",),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the data\n",
    "The joint table uses track ids and offensiveness categories as indices. This is what we want, but we still have individual cells for every word.\n",
    "\n",
    "Now we aggregate the items for every index. We sum the entries. This gives us the total count of words in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_indexed.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id            category  strength  target\n",
       "TRAAAAV128F421A322  NaN       NaN       NaN       6\n",
       "                                        NaN       4\n",
       "                                        NaN       2\n",
       "                                        NaN       2\n",
       "                                        NaN       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_indexed_filtered = joint_indexed[\"count\"]\n",
    "joint_indexed_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joint_aggregated = joint_indexed_filtered.agg(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offensiveness_rating = joint_indexed_filtered.groupby(str, axis=0).agg(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TRAAAAV128F421A322', 'non-discriminatory', 'mild', nan)      1\n",
       "('TRAAAAV128F421A322', nan, nan, nan)                        102\n",
       "('TRAAABD128F429CF47', nan, nan, nan)                        226\n",
       "('TRAAAED128E0783FAB', nan, nan, nan)                        421\n",
       "('TRAAAEF128F4273421', nan, nan, nan)                        139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offensiveness_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offensiveness_rating.to_pickle(\"../pickles/offensiveness_rating_structured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's it for now ! We have a way to measure the offensiveness of a track on multiple criteria. Now we need another measure: the popularity of a song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity of songs (song hotness, or \"hotttnesss\" ???)\n",
    "In this section we are going to look at the million-song dataset and we are going to try to get the popularity of a song. The million-song dataset has a special structure. There are 26 folders A, B, C, ..., Z. Folder A has recursively 26 subfolders which have again 26 subfolders and so on and the last subfolders have a certain number of h5 files. Each of these h5 files contain all information about one track and the name of the file is simply the track id followed by the extension \".h5\". \n",
    "\n",
    "Now the size of the dataset is pretty challenging since the compressed files A.tar.gz, B.tar.gz, ..., Z.tar.gz each have a size of approximately 7.5Gb. So we will start by taking a closer look at the A.tar.gz sample. For that we go to the cluster with ssh, we download A.tar.gz to our home folder and then we simply use scp on our computer to go grab that A.tar.gz file. Now, on our computer we unzip A.tar.gz and now we have a nice A folder containing the 26-th of all our songs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_dir_data = r'../../'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read one track with our `h5py` tool just to see where everything is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(os.path.join(base_dir_data, \"A/A/A/TRAAAAK128F9318786.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to open this file manually with [HDFView](https://support.hdfgroup.org/products/java/hdfview/) in order to inspect it before doing any code analysis. We see that it has 3 folders: analysis, metadata and musicbrainz. The analysis folder contains all the information about the musical instruments and how they're played. This is clearly the biggest folder. The musicbrainz doesn't seem to contain much. It could be useful if we decide to use the [MusicBrainz](https://musicbrainz.org/) website. Anyway, we are interested in the metadata folder and more precisely in the metadata/songs file. That file contains the \"song_hotttnesss\" (can't understand why 3 \"t\"s and 3 \"s\"s attribute which seems to be a value between 0 and 1 and this attribute corresponds to the popularity the song. So let's get it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_songs = f[\"metadata/songs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CLASS', b'TABLE'),\n",
       " ('VERSION', b'2.6'),\n",
       " ('TITLE', b'table of metadata for one song'),\n",
       " ('FIELD_0_NAME', b'analyzer_version'),\n",
       " ('FIELD_1_NAME', b'artist_7digitalid'),\n",
       " ('FIELD_2_NAME', b'artist_familiarity'),\n",
       " ('FIELD_3_NAME', b'artist_hotttnesss'),\n",
       " ('FIELD_4_NAME', b'artist_id'),\n",
       " ('FIELD_5_NAME', b'artist_latitude'),\n",
       " ('FIELD_6_NAME', b'artist_location'),\n",
       " ('FIELD_7_NAME', b'artist_longitude'),\n",
       " ('FIELD_8_NAME', b'artist_mbid'),\n",
       " ('FIELD_9_NAME', b'artist_name'),\n",
       " ('FIELD_10_NAME', b'artist_playmeid'),\n",
       " ('FIELD_11_NAME', b'genre'),\n",
       " ('FIELD_12_NAME', b'idx_artist_terms'),\n",
       " ('FIELD_13_NAME', b'idx_similar_artists'),\n",
       " ('FIELD_14_NAME', b'release'),\n",
       " ('FIELD_15_NAME', b'release_7digitalid'),\n",
       " ('FIELD_16_NAME', b'song_hotttnesss'),\n",
       " ('FIELD_17_NAME', b'song_id'),\n",
       " ('FIELD_18_NAME', b'title'),\n",
       " ('FIELD_19_NAME', b'track_7digitalid'),\n",
       " ('FIELD_0_FILL', b''),\n",
       " ('FIELD_1_FILL', 0),\n",
       " ('FIELD_2_FILL', 0.0),\n",
       " ('FIELD_3_FILL', 0.0),\n",
       " ('FIELD_4_FILL', b''),\n",
       " ('FIELD_5_FILL', 0.0),\n",
       " ('FIELD_6_FILL', b''),\n",
       " ('FIELD_7_FILL', 0.0),\n",
       " ('FIELD_8_FILL', b''),\n",
       " ('FIELD_9_FILL', b''),\n",
       " ('FIELD_10_FILL', 0),\n",
       " ('FIELD_11_FILL', b''),\n",
       " ('FIELD_12_FILL', 0),\n",
       " ('FIELD_13_FILL', 0),\n",
       " ('FIELD_14_FILL', b''),\n",
       " ('FIELD_15_FILL', 0),\n",
       " ('FIELD_16_FILL', 0.0),\n",
       " ('FIELD_17_FILL', b''),\n",
       " ('FIELD_18_FILL', b''),\n",
       " ('FIELD_19_FILL', 0),\n",
       " ('NROWS', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(metadata_songs.attrs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we see that the \"FIELD_16_NAME\" corresponds to the song hotness attribute. let's look with closer details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (b'', 324573,  0.63990252,  0.46131834, b'ARJNIUY12298900C91',  nan, b'',  nan, b'6ae6a016-91d7-46cc-be7d-5e8e5d320c54', b'Adelitas Way', 166043, b'', 0, 0, b'Adelitas Way', 497103,  0.73337162, b'SOBLFFE12AF72AA5BA', b'Scream', 5504670)],\n",
       "      dtype=[('analyzer_version', 'S32'), ('artist_7digitalid', '<i4'), ('artist_familiarity', '<f8'), ('artist_hotttnesss', '<f8'), ('artist_id', 'S32'), ('artist_latitude', '<f8'), ('artist_location', 'S1024'), ('artist_longitude', '<f8'), ('artist_mbid', 'S40'), ('artist_name', 'S1024'), ('artist_playmeid', '<i4'), ('genre', 'S1024'), ('idx_artist_terms', '<i4'), ('idx_similar_artists', '<i4'), ('release', 'S1024'), ('release_7digitalid', '<i4'), ('song_hotttnesss', '<f8'), ('song_id', 'S32'), ('title', 'S1024'), ('track_7digitalid', '<i4')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_songs.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we see that the song hotness is the element at index 16 of the `value` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333716199617285"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_songs.value[0][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to generalize this to all of A folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_files(basedir, ext='.h5'):\n",
    "    hotness = []\n",
    "    track_ids = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root, '*'+ext))\n",
    "        for f in files:\n",
    "            h5_file = h5py.File(str(f))\n",
    "            song_hotttnesss = h5_file[\"metadata/songs\"].value[0][16]\n",
    "            track_ids.append(f.split(\"/\")[-1].split(\".\")[0])\n",
    "            hotness.append(song_hotttnesss)\n",
    "    return pd.DataFrame(data={\"id\" : track_ids, \"hotttnesss\": hotness})\n",
    "\n",
    "song_hotness_A = count_all_files(r'../../A/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it ! We now have a nice pandas frame containing the track ids with the hotness of the corresponding song:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotttnesss</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>TRARRQU128F427DAD3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.524822</td>\n",
       "      <td>TRARRAO128F145D072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TRARRWA128F42A0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204543</td>\n",
       "      <td>TRARRYB128F426BC39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TRARRNK12903D0C0DA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hotttnesss                  id\n",
       "0    0.000000  TRARRQU128F427DAD3\n",
       "1    0.524822  TRARRAO128F145D072\n",
       "2         NaN  TRARRWA128F42A0195\n",
       "3    0.204543  TRARRYB128F426BC39\n",
       "4         NaN  TRARRNK12903D0C0DA"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not convinced, you can take rows at random and go see in the h5 file if the value you have corresponds to the value \"song_hotttnesss\" in the h5 file. Now we will need a fast way to find a song given its track id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness_A = song_hotness_A.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotttnesss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRARRQU128F427DAD3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARRAO128F145D072</th>\n",
       "      <td>0.524822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARRWA128F42A0195</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARRYB128F426BC39</th>\n",
       "      <td>0.204543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARRNK12903D0C0DA</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    hotttnesss\n",
       "id                            \n",
       "TRARRQU128F427DAD3    0.000000\n",
       "TRARRAO128F145D072    0.524822\n",
       "TRARRWA128F42A0195         NaN\n",
       "TRARRYB128F426BC39    0.204543\n",
       "TRARRNK12903D0C0DA         NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we don't want to lose this so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness_A.to_csv(os.path.join(base_dir_data, \"csv_hotness_files/A_hotness.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it ! We have our csv data for A. But now we have 25 other folders to process and there's no way we are going to download each manually on our small computers (moreover it takes much time to download them). So this is what we are doing. We are creating a bash script for processing all the files directly on the cluster:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "set -e\n",
    "\n",
    "declare -a filenames=(\"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\"\n",
    "            \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\")\n",
    "\n",
    "for letter in \"${filenames[@]}\"\n",
    "do\n",
    "    eval \"hadoop fs -getmerge /datasets/million-song/$letter.tar.gz ~/$letter.tar.gz\"\n",
    "    eval \"tar -zxvf $letter.tar.gz\"\n",
    "    eval \"rm $letter.tar.gz\"\n",
    "    eval \"python script_h5_to_csv.py $letter\"\n",
    "    eval \"rm -r $letter\"\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in short, we copy the hdfs file to our local folder, we unzip it, we remove the compressed version, we process it and get the csv the same way we did it for A and, finally, we remove the folder (yes I am too lazy to go search how we convert ASCII numbers to characters in bash so I created the alphabet array manually). The \"script_h5_to_csv.py\" contains the following code (which is the same we did for A above in the notebook):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "def count_all_files(basedir, ext='.h5'):\n",
    "    hotness = []\n",
    "    track_ids = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root, '*'+ext))\n",
    "        for f in files:\n",
    "            h5_file = h5py.File(str(f))\n",
    "            song_hotttnesss = h5_file[\"metadata/songs\"].value[0][16]\n",
    "            track_ids.append(f.split(\"/\")[-1].split(\".\")[0])\n",
    "            hotness.append(song_hotttnesss)\n",
    "    return pd.DataFrame(data={\"id\" : track_ids, \"hotttnesss\": hotness})\n",
    "\n",
    "song_hotness_A = count_all_files(sys.argv[1])\n",
    "song_hotness_A.to_csv(\"{}_hotness.csv\".format(sys.argv[1]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [tmux](https://github.com/tmux/tmux/wiki) to let the script run during the night and that's it, We have our csv files containing the hotness for our entire set of one million songs !\n",
    "\n",
    "Now we want to combine this information with the [Musixmatch](https://www.musixmatch.com/fr) lyrics dataset because we need the lyrics if we want to do any processing. This is why we are going to keep only the tracks for which we have the lyrics. So let's get all those tracks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TRAAAAV128F421A322',),\n",
       " ('TRAAABD128F429CF47',),\n",
       " ('TRAAAED128E0783FAB',),\n",
       " ('TRAAAEF128F4273421',),\n",
       " ('TRAAAEW128F42930C0',)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../../mxm_dataset.db.1\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT DISTINCT track_id FROM lyrics ORDER BY track_id;\")\n",
    "track_ids = cursor.fetchall()\n",
    "cursor.close()\n",
    "track_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all hotness csv files into one big dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_hotness_files = glob.glob(os.path.join(base_dir_data, \"csv_hotness_files/*_hotness.csv\"))\n",
    "\n",
    "list_all_frames = []\n",
    "for csv in all_csv_hotness_files:\n",
    "    df = pd.read_csv(csv)\n",
    "    list_all_frames.append(df[[\"id\", \"hotttnesss\"]])\n",
    "\n",
    "song_hotness = pd.concat(list_all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, we have one million songs ! Now let's just save this dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness.to_csv(os.path.join(base_dir_data, \"csv_hotness_files/hotness.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness = song_hotness.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we take only the songs where we have the lyrics in the Musixmatch dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237662/237662 [2:19:48<00:00, 28.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_lyrics_only_hotness():\n",
    "    result = pd.DataFrame(columns=[\"hotness\"])\n",
    "    for i in tqdm(range(len(track_ids))):\n",
    "        track_id = track_ids[i][0]\n",
    "        if track_id in song_hotness.index:\n",
    "            hotness = song_hotness.loc[track_id][\"hotttnesss\"]\n",
    "            result.loc[track_id] = [hotness]\n",
    "    return result\n",
    "\n",
    "song_hotness_lyrics = get_lyrics_only_hotness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow ! Lasted more than 2 hours on a laptop. Probably should have done it on the cluster (or optimized it a little bit) We can't lose this so let's save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_hotness_lyrics.to_csv(os.path.join(base_dir_data, \"csv_hotness_files/hotness_lyrics.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our dataframe with the popularity (hotness) for all songs where we have lyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAAAAV128F421A322</th>\n",
       "      <td>0.481694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAABD128F429CF47</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAED128E0783FAB</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAEF128F4273421</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAEW128F42930C0</th>\n",
       "      <td>0.407902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hotness\n",
       "TRAAAAV128F421A322  0.481694\n",
       "TRAAABD128F429CF47       NaN\n",
       "TRAAAED128E0783FAB       NaN\n",
       "TRAAAEF128F4273421       NaN\n",
       "TRAAAEW128F42930C0  0.407902"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness_lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we see that there are a lot of NaN values (songs for which the popularity was not measured). Let's just describe the frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.475753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.360371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.508289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.621942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             hotness\n",
       "count  170573.000000\n",
       "mean        0.475753\n",
       "std         0.209909\n",
       "min         0.000000\n",
       "25%         0.360371\n",
       "50%         0.508289\n",
       "75%         0.621942\n",
       "max         1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_hotness_lyrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the min is 0 and the max is 1, which indicates that we didn't do mistakes and that the dataset is pretty clean (there are no strange negative or greater than 1 values). We also see that we have 170573 \"usable\" datapoints, i.e. songs where we have the hotness value and the lyrics for further offensiveness analysis. On the one hand, that's less than 20% of the million songs but one the other it is still 170 thousands which makes quite a lot of data ! Let's plot the histograms here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff064751128>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF0RJREFUeJzt3W+MXfWd3/H3JzjLuqQQAtkRNWxNi/vH4IYsLmt1o2o2\naBeHfQCRIHKKAtlQnAo2ykp+sJAHTbaRJZBKaKELrbMgG8QGLJLUNIGtKGSaRrs266wIxhCaaSCL\nXQIKsBBTQTPk2wfzm+1ljp25vjO+1+N5v6Sre+73nt85v688ns8995x7J1WFJEm93jXqCUiSjj6G\ngySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdy0Y9gUGdeuqptXLlyoHGvvHGG5xw\nwgkLO6GjnD0vDfa8NMyn5+9+97s/qar3z7Xeog2HlStXsnv37oHGTkxMMD4+vrATOsrZ89Jgz0vD\nfHpO8qN+1vNtJUlSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUsei/YS0dLRa\ned03R7bvreuX1tdI6MjxyEGS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRh\nOEiSOuYMhyS/nOSxJN9LsjfJH7b6F5LsT/J4u13UM+b6JJNJnklyYU/9vCR72nO3JEmrH5/kvlbf\nlWTlwrcqSepXP0cObwEfrqoPAOcC65Osa8/dXFXnttuDAElWAxuAs4H1wG1Jjmvr3w5cDaxqt/Wt\nfhXwalWdBdwM3Dj/1iRJg5ozHGragfbw3e1Wv2DIxcC9VfVWVT0LTALnJzkNOLGqdlZVAXcBl/SM\n2daW7wcumDmqkCQNX1/nHJIcl+Rx4CXg4ara1Z76TJInktyZ5ORWWwE83zN8X6utaMuz6+8YU1VT\nwGvAKQP0I0laAH19ZXdVvQ2cm+S9wNeTnMP0W0RfZPoo4ovATcCnjtREAZJsBDYCjI2NMTExMdB2\nDhw4MPDYxcqeh2fTmqmh73OG/85LwzB6Pqy/51BVf53kW8D6qvq3M/UkXwa+0R7uB87oGXZ6q+1v\ny7PrvWP2JVkGnAS8fJD9bwG2AKxdu7bGx8cPZ/p/Y2JigkHHLlb2PDyfHPHfc/Df+dg3jJ77uVrp\n/e2IgSTLgd8Cvt/OIcz4KPBkW34A2NCuQDqT6RPPj1XVC8DrSda18wlXADt6xlzZli8FHm3nJSRJ\nI9DPkcNpwLZ2xdG7gO1V9Y0kdyc5l+m3lZ4DPg1QVXuTbAeeAqaAa9vbUgDXAFuB5cBD7QZwB3B3\nkkngFaavdpIkjcic4VBVTwAfPEj9E79gzGZg80Hqu4FzDlJ/E7hsrrlIkobDT0hLkjoMB0lSh+Eg\nSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2H9fccpMVkz/7XRvq3\nFaTFzCMHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpI45wyHJLyd5LMn3kuxN8oet/r4kDyf5Qbs/\nuWfM9UkmkzyT5MKe+nlJ9rTnbkmSVj8+yX2tvivJyoVvVZLUr36OHN4CPlxVHwDOBdYnWQdcBzxS\nVauAR9pjkqwGNgBnA+uB25Ic17Z1O3A1sKrd1rf6VcCrVXUWcDNw4wL0Jkka0JzhUNMOtIfvbrcC\nLga2tfo24JK2fDFwb1W9VVXPApPA+UlOA06sqp1VVcBds8bMbOt+4IKZowpJ0vD19Qnp9sr/u8BZ\nwB9V1a4kY1X1Qlvlx8BYW14B7OwZvq/VftaWZ9dnxjwPUFVTSV4DTgF+MmseG4GNAGNjY0xMTPQz\n/Y4DBw4MPHaxWoo9jy2HTWumRj2NoXrplde49Z4dQ9/vmhUnDX2fM5biz/Yweu4rHKrqbeDcJO8F\nvp7knFnPV5I6EhOctZ8twBaAtWvX1vj4+EDbmZiYYNCxi9VS7PnWe3Zw056l9Q0xm9ZMjaTn5y4f\nH/o+ZyzFn+1h9HxYVytV1V8D32L6XMGL7a0i2v1LbbX9wBk9w05vtf1teXb9HWOSLANOAl4+nLlJ\nkhZOP1crvb8dMZBkOfBbwPeBB4Ar22pXAjPHsg8AG9oVSGcyfeL5sfYW1OtJ1rXzCVfMGjOzrUuB\nR9t5CUnSCPRz/HkasK2dd3gXsL2qvpHkz4HtSa4CfgR8DKCq9ibZDjwFTAHXtrelAK4BtgLLgYfa\nDeAO4O4kk8ArTF/tJEkakTnDoaqeAD54kPrLwAWHGLMZ2HyQ+m7gnIPU3wQu62O+kqQh8BPSkqQO\nw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAc\nJEkdhoMkqcNwkCR1GA6SpA7DQZLUMWc4JDkjybeSPJVkb5LPtvoXkuxP8ni7XdQz5vokk0meSXJh\nT/28JHvac7ckSasfn+S+Vt+VZOXCtypJ6lc/Rw5TwKaqWg2sA65Nsro9d3NVndtuDwK05zYAZwPr\ngduSHNfWvx24GljVbutb/Srg1ao6C7gZuHH+rUmSBjVnOFTVC1X1l235p8DTwIpfMORi4N6qequq\nngUmgfOTnAacWFU7q6qAu4BLesZsa8v3AxfMHFVIkobvsM45tLd7PgjsaqXPJHkiyZ1JTm61FcDz\nPcP2tdqKtjy7/o4xVTUFvAaccjhzkyQtnGX9rpjkPcBXgd+vqteT3A58Eah2fxPwqSMyy/8/h43A\nRoCxsTEmJiYG2s6BAwcGHrtYLcWex5bDpjVTo57GUI2q51H+bC3Fn+1h9NxXOCR5N9PBcE9VfQ2g\nql7sef7LwDfaw/3AGT3DT2+1/W15dr13zL4ky4CTgJdnz6OqtgBbANauXVvj4+P9TL9jYmKCQccu\nVkux51vv2cFNe/p+/XNM2LRmaiQ9P3f5+ND3OWMp/mwPo+d+rlYKcAfwdFV9qad+Ws9qHwWebMsP\nABvaFUhnMn3i+bGqegF4Pcm6ts0rgB09Y65sy5cCj7bzEpKkEejnJcZvAJ8A9iR5vNU+B3w8yblM\nv630HPBpgKram2Q78BTTVzpdW1Vvt3HXAFuB5cBD7QbT4XN3kkngFaavdpIkjcic4VBV3wEOduXQ\ng79gzGZg80Hqu4FzDlJ/E7hsrrlIkobDT0hLkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQO\nw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6pgz\nHJKckeRbSZ5KsjfJZ1v9fUkeTvKDdn9yz5jrk0wmeSbJhT3185Lsac/dkiStfnyS+1p9V5KVC9+q\nJKlf/Rw5TAGbqmo1sA64Nslq4DrgkapaBTzSHtOe2wCcDawHbktyXNvW7cDVwKp2W9/qVwGvVtVZ\nwM3AjQvQmyRpQHOGQ1W9UFV/2ZZ/CjwNrAAuBra11bYBl7Tli4F7q+qtqnoWmATOT3IacGJV7ayq\nAu6aNWZmW/cDF8wcVUiShm/Z4azc3u75ILALGKuqF9pTPwbG2vIKYGfPsH2t9rO2PLs+M+Z5gKqa\nSvIacArwk1n73whsBBgbG2NiYuJwpv83Dhw4MPDYxWop9jy2HDatmRr1NIZqVD2P8mdrKf5sD6Pn\nvsMhyXuArwK/X1Wv976wr6pKUkdgfu9QVVuALQBr166t8fHxgbYzMTHBoGMXq6XY86337OCmPYf1\n+mfR27RmaiQ9P3f5+ND3OWMp/mwPo+e+rlZK8m6mg+GeqvpaK7/Y3iqi3b/U6vuBM3qGn95q+9vy\n7Po7xiRZBpwEvHy4zUiSFkY/VysFuAN4uqq+1PPUA8CVbflKYEdPfUO7AulMpk88P9begno9ybq2\nzStmjZnZ1qXAo+28hCRpBPo5/vwN4BPAniSPt9rngBuA7UmuAn4EfAygqvYm2Q48xfSVTtdW1dtt\n3DXAVmA58FC7wXT43J1kEniF6audJEkjMmc4VNV3gENdOXTBIcZsBjYfpL4bOOcg9TeBy+aaiyRp\nOJbW2TqNxMrrvjmS/W5aM5LdSscEvz5DktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6S\npA7DQZLUYThIkjoMB0lSh+EgSerwi/eWiD37X+OTI/oCPEmLj0cOkqQOw0GS1GE4SJI6DAdJUsec\n4ZDkziQvJXmyp/aFJPuTPN5uF/U8d32SySTPJLmwp35ekj3tuVuSpNWPT3Jfq+9KsnJhW5QkHa5+\njhy2AusPUr+5qs5ttwcBkqwGNgBntzG3JTmurX87cDWwqt1mtnkV8GpVnQXcDNw4YC+SpAUyZzhU\n1beBV/rc3sXAvVX1VlU9C0wC5yc5DTixqnZWVQF3AZf0jNnWlu8HLpg5qpAkjcZ8PufwmSRXALuB\nTVX1KrAC2Nmzzr5W+1lbnl2n3T8PUFVTSV4DTgF+Mo+5SRqilSP8DM3W9SeMbN/HskHD4Xbgi0C1\n+5uATy3UpA4lyUZgI8DY2BgTExMDbefAgQMDj12sxpbDpjVTo57GUNnz0rAU/z8Po+eBwqGqXpxZ\nTvJl4Bvt4X7gjJ5VT2+1/W15dr13zL4ky4CTgJcPsd8twBaAtWvX1vj4+CDT59Z7dnDTd94YaOx8\nPXfD74xkv7fes4Ob9iytD8RvWjNlz0vA1vUnMOjvgsVqYmLiiPc80KWs7RzCjI8CM1cyPQBsaFcg\nncn0iefHquoF4PUk69r5hCuAHT1jrmzLlwKPtvMSkqQRmfMlRpKvAOPAqUn2AZ8HxpOcy/TbSs8B\nnwaoqr1JtgNPAVPAtVX1dtvUNUxf+bQceKjdAO4A7k4yyfSJ7w0L0ZgkaXBzhkNVffwg5Tt+wfqb\ngc0Hqe8GzjlI/U3gsrnmIUkaHj8hLUnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH\n4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHXOGQ5I7k7yU5Mme\n2vuSPJzkB+3+5J7nrk8ymeSZJBf21M9Lsqc9d0uStPrxSe5r9V1JVi5si5Kkw9XPkcNWYP2s2nXA\nI1W1CnikPSbJamADcHYbc1uS49qY24GrgVXtNrPNq4BXq+os4GbgxkGbkSQtjDnDoaq+Dbwyq3wx\nsK0tbwMu6anfW1VvVdWzwCRwfpLTgBOramdVFXDXrDEz27ofuGDmqEKSNBqDnnMYq6oX2vKPgbG2\nvAJ4vme9fa22oi3Prr9jTFVNAa8Bpww4L0nSAlg23w1UVSWphZjMXJJsBDYCjI2NMTExMdB2xpbD\npjVTCziz/g065/kaZc+jYs9Lw4EDB0b2/2pUhtHzoOHwYpLTquqF9pbRS62+HzijZ73TW21/W55d\n7x2zL8ky4CTg5YPttKq2AFsA1q5dW+Pj4wNN/tZ7dnDTnnnn4kCeu3x8JPsdZc+jsmnNlD0vAVvX\nn8CgvwsWq4mJiSPe86BvKz0AXNmWrwR29NQ3tCuQzmT6xPNj7S2o15Osa+cTrpg1ZmZblwKPtvMS\nkqQRmfMlRpKvAOPAqUn2AZ8HbgC2J7kK+BHwMYCq2ptkO/AUMAVcW1Vvt01dw/SVT8uBh9oN4A7g\n7iSTTJ/43rAgnUmSBjZnOFTVxw/x1AWHWH8zsPkg9d3AOQepvwlcNtc8JEnD4yekJUkdhoMkqcNw\nkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJ\nUofhIEnqMBwkSR2GgySpw3CQJHXMKxySPJdkT5LHk+xutfcleTjJD9r9yT3rX59kMskzSS7sqZ/X\ntjOZ5JYkmc+8JEnzsxBHDr9ZVedW1dr2+DrgkapaBTzSHpNkNbABOBtYD9yW5Lg25nbgamBVu61f\ngHlJkgZ0JN5WuhjY1pa3AZf01O+tqreq6llgEjg/yWnAiVW1s6oKuKtnjCRpBJbNc3wB/y3J28B/\nqqotwFhVvdCe/zEw1pZXADt7xu5rtZ+15dn1jiQbgY0AY2NjTExMDDTpseWwac3UQGPna9A5z9co\nex4Ve14aDhw4MLL/V6MyjJ7nGw4fqqr9SX4FeDjJ93ufrKpKUvPcR+/2tgBbANauXVvj4+MDbefW\ne3Zw0575tj6Y5y4fH8l+R9nzqGxaM2XPS8DW9Scw6O+CxWpiYuKI9zyvt5Wqan+7fwn4OnA+8GJ7\nq4h2/1JbfT9wRs/w01ttf1ueXZckjcjALzGSnAC8q6p+2pZ/G/g3wAPAlcAN7X5HG/IA8CdJvgT8\nHaZPPD9WVW8neT3JOmAXcAVw66DzkrS07Nn/Gp+87ptD3+9zN/zO0Pc5TPM5/hwDvt6uOl0G/ElV\n/WmSvwC2J7kK+BHwMYCq2ptkO/AUMAVcW1Vvt21dA2wFlgMPtZskaUQGDoeq+iHwgYPUXwYuOMSY\nzcDmg9R3A+cMOhdJ0sLyE9KSpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQO\nw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktQxn78hvaCSrAf+PXAc8MdV\ndcOIpyRJh7Tyum+ObN9b159wxPdxVBw5JDkO+CPgI8Bq4ONJVo92VpK0dB0V4QCcD0xW1Q+r6v8C\n9wIXj3hOkrRkHS1vK60Anu95vA/49RHN5Yga1aHopjUj2a2kRSpVNeo5kORSYH1V/cv2+BPAr1fV\n781abyOwsT38h8AzA+7yVOAnA45drOx5abDnpWE+Pf/dqnr/XCsdLUcO+4Ezeh6f3mrvUFVbgC3z\n3VmS3VW1dr7bWUzseWmw56VhGD0fLecc/gJYleTMJL8EbAAeGPGcJGnJOiqOHKpqKsnvAf+V6UtZ\n76yqvSOeliQtWUdFOABU1YPAg0Pa3bzfmlqE7HlpsOel4Yj3fFSckJYkHV2OlnMOkqSjyDEdDknW\nJ3kmyWSS6w7yfJLc0p5/IsmvjWKeC6mPni9vve5J8mdJPjCKeS6kuXruWe+fJplql04vav30nGQ8\nyeNJ9ib578Oe40Lq4+f6pCT/Jcn3Wr+/O4p5LqQkdyZ5KcmTh3j+yP7+qqpj8sb0ie3/Bfw94JeA\n7wGrZ61zEfAQEGAdsGvU8x5Cz/8MOLktf2Qp9Nyz3qNMn9e6dNTzHsK/83uBp4BfbY9/ZdTzPsL9\nfg64sS2/H3gF+KVRz32eff9z4NeAJw/x/BH9/XUsHzn085UcFwN31bSdwHuTnDbsiS6gOXuuqj+r\nqlfbw51Mf6ZkMev3q1c+A3wVeGmYkztC+un5XwBfq6q/Aqiqxdx3P/0W8LeTBHgP0+EwNdxpLqyq\n+jbTfRzKEf39dSyHw8G+kmPFAOssJofbz1VMv/JYzObsOckK4KPA7UOc15HUz7/zPwBOTjKR5LtJ\nrhja7BZeP/3+B+AfA/8b2AN8tqp+PpzpjcwR/f111FzKquFK8ptMh8OHRj2XIfh3wB9U1c+nX1gu\nCcuA84ALgOXAnyfZWVX/c7TTOmIuBB4HPgz8feDhJP+jql4f7bQWr2M5HPr5So6+vrZjEemrnyT/\nBPhj4CNV9fKQ5nak9NPzWuDeFgynAhclmaqq/zycKS64fnreB7xcVW8AbyT5NvABYDGGQz/9/i5w\nQ02/GT+Z5FngHwGPDWeKI3FEf38dy28r9fOVHA8AV7Sz/uuA16rqhWFPdAHN2XOSXwW+BnziGHkV\nOWfPVXVmVa2sqpXA/cA1izgYoL+f7R3Ah5IsS/K3mP6W46eHPM+F0k+/f8X0URJJxpj+Ys4fDnWW\nw3dEf38ds0cOdYiv5Ejyr9rz/5HpK1cuAiaB/8P0q49Fq8+e/zVwCnBbeyU9VYv4S8v67PmY0k/P\nVfV0kj8FngB+zvRfVzzoJZFHuz7/jb8IbE2yh+mrd/6gqhb1N7Um+QowDpyaZB/weeDdMJzfX35C\nWpLUcSy/rSRJGpDhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOv4fAGjarVPcbewAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff05dd20e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "song_hotness_lyrics.hotness.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to look like a gaussian, except for these 0 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14756 songs with hotness 0\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} songs with hotness 0\".format(song_hotness_lyrics[song_hotness_lyrics[\"hotness\"] == 0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That makes almost 15000 songs for which we are somehow \"unsure\" about. Are those really songs with 0 popularity ?! Maybe they really didn't touch anyone or very few people. But let's look at the bright side: even if we cut them out in our analysis, we are still left with approximately 155000 songs for which we know the popularity value and the lyrics. But we still have to decide what we will do with these 15000 songs, will we keep them or exclude them ? Maybe we will keep them and treat them separately also. \n",
    "\n",
    "Anyway, Million Song and Echo Nest have our back covered: we can use another popularity measure which is the play count ! But this value is present in [another dataset](https://labrosa.ee.columbia.edu/millionsong/tasteprofile). If this doesn't work work we might also use the [Yahoo ratings dataset](https://labrosa.ee.columbia.edu/millionsong/pages/tasks-demos#yahoodata) but this one is for artist rating more than song rating so we should be careful if we decide to include it too. So let's proceed with Taste Profile !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity of a song: the play counts\n",
    "In this section we look at the number of times a song has been played (the play count) using [this](https://labrosa.ee.columbia.edu/millionsong/tasteprofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAY_COUNTS_FILE = \"train_triplets.txt\"\n",
    "SONGS_COUNTS_FILE = \"songs-counts.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *train_triplets.txt* file contains triplets of (User, Song, Play count) and it's almost 3GB large. It contains no header and is *Tab* separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>songs</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAPDEY12A81C210A9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFNSP12AF72A0E22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFOVM12A58A7D494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBNZDC12A6D4FC103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBSUJE12A6D4F8CF5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBVFZR12A6D4F8AE3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXALG12A8C13C108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXHDL12A81C204C0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      users               songs  counts\n",
       "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995       1\n",
       "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9       1\n",
       "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B       2\n",
       "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22       1\n",
       "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494       1\n",
       "5  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBNZDC12A6D4FC103       1\n",
       "6  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBSUJE12A6D4F8CF5       2\n",
       "7  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBVFZR12A6D4F8AE3       1\n",
       "8  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXALG12A8C13C108       1\n",
       "9  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0       1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_counts = pd.read_table(PLAY_COUNTS_FILE, header=None, names=[\"users\",\"songs\",\"counts\"])\n",
    "play_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.837359e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.866859e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.437725e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.667000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             counts\n",
       "count  4.837359e+07\n",
       "mean   2.866859e+00\n",
       "std    6.437725e+00\n",
       "min    1.000000e+00\n",
       "25%    1.000000e+00\n",
       "50%    1.000000e+00\n",
       "75%    3.000000e+00\n",
       "max    9.667000e+03"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is the mapping song -> play count. We'll produce a new file containing only this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>songs</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SOAAADD12AB018A9DD</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAAADE12A6D4F80CC</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAAADF12A8C13DF62</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAAADZ12A8C1334FB</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAAAFI12A6D4F9C66</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    counts\n",
       "songs                     \n",
       "SOAAADD12AB018A9DD      24\n",
       "SOAAADE12A6D4F80CC      12\n",
       "SOAAADF12A8C13DF62       9\n",
       "SOAAADZ12A8C1334FB      12\n",
       "SOAAAFI12A6D4F9C66     188"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_counts = play_counts.groupby(by=\"songs\").sum()\n",
    "songs_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>384546.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>360.633690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3256.809395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>726885.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              counts\n",
       "count  384546.000000\n",
       "mean      360.633690\n",
       "std      3256.809395\n",
       "min         1.000000\n",
       "25%         8.000000\n",
       "50%        32.000000\n",
       "75%       133.000000\n",
       "max    726885.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 384546 songs at disposal here. We also see that there is a huge gap between the minimal number of play counts (1) and the maximal (726885). This indicates simply that songs which are popular are really popular !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x191027b0c18>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19102766978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Distribution of log of counts\")\n",
    "sns.distplot(songs_counts.apply(np.log), kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just want to save everything so we don't lose it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_counts.to_csv(SONGS_COUNTS_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
